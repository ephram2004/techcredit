{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ec0f76-970a-47cd-aa1e-0a2e1a6ad92f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preview from LangChain\n",
    "\n",
    "## Step by step code\n",
    "\n",
    "1. get LangSmith API Key from environment\n",
    "2. set up anthropic key for chat model\n",
    "3. set up embedding model for embeddings\n",
    "4. select vector database\n",
    "5. set up document loader and split up\n",
    "\n",
    "## Set up API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8825c3-e6e4-4541-aa62-fc862ba42bc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tutorials\n",
    "LangChain RAG tutorial document\n",
    "Part 1\n",
    "https://python.langchain.com/docs/tutorials/rag\n",
    "\n",
    "Part 2\n",
    "extends the implementation to accommodate conversation-style interactions and\n",
    "multi-step retrieval processes.\n",
    "https://python.langchain.com/docs/tutorials/qa_chat_history/\n",
    "\n",
    "LangChain document loader for GitHub Repo\n",
    "https://python.langchain.com/docs/integrations/document_loaders/github/\n",
    "\n",
    "LangChain document loader for Git Repository\n",
    "https://python.langchain.com/docs/integrations/document_loaders/git/\n",
    "\n",
    "LangChain document loader for Source Code (e.g. Python)\n",
    "https://python.langchain.com/docs/integrations/document_loaders/source_code/\n",
    "\n",
    "LangSmith evaluation for a chatbot\n",
    "https://docs.smith.langchain.com/evaluation/tutorials/evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00262b7-72d9-4472-bdcb-f1a85e3321eb",
   "metadata": {},
   "source": [
    "* [X] set up LangSmith key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f79f4383-61f6-41d8-9536-0873e426f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for LangSmith to enable tracing:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith to enable tracing: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36908430-f05f-4d6f-ae67-cafb09ed39db",
   "metadata": {},
   "source": [
    "* [X] set up Anthropic key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac315b7b-3b72-4f20-a641-9b2b498a7100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for Anthropic:  ········\n"
     ]
    }
   ],
   "source": [
    "if not os.environ.get(\"ANTHROPIC_API_KEY\"):\n",
    "  os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter API key for Anthropic: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"claude-3-5-haiku-latest\", model_provider=\"anthropic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032cc2a-ae18-40bf-86aa-08270b25fc32",
   "metadata": {},
   "source": [
    "* [X] set up Google gemini as embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b61b89-8f2b-4d42-b768-cba7f2ce3a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for Google Gemini:  ········\n"
     ]
    }
   ],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7a684-56c6-40e1-8a64-b86089a6e12c",
   "metadata": {},
   "source": [
    "* [X] set up vector database \n",
    "\n",
    "# Choosing database\n",
    "\n",
    "Load, chunk, split, embed and vectorize code data and document data into database\n",
    "\n",
    "## Candidates\n",
    "\n",
    "1. cassandra\n",
    "2. open search https://opensearch.org/platform/os-search/vector-database/\n",
    "3. Pinecone\n",
    "4. MongoDB\n",
    "5. PostgreSQL\n",
    "6. [X] Chroma, locally hosted with sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5954c2e3-3c86-41f1-9ce2-d76e5fb88ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"python_tech_credit\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "document_store = Chroma(\n",
    "    collection_name=\"document_tech_credit\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf0591-3020-489b-9563-00a12e3a20bb",
   "metadata": {},
   "source": [
    "* [ ] Import and load a GitHub Repo as a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ee1cb4-7571-4e12-a190-58e53b4d6be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter ACCESS_TOKEN for GitHub:  ········\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import GithubFileLoader\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "from code_splitter import Language, TiktokenSplitter\n",
    "\n",
    "if not os.environ.get(\"GITHUB_PERSONAL_ACCESS_TOKEN\"):\n",
    "   os.environ[\"GITHUB_PERSONAL_ACCESS_TOKEN\"] = getpass.getpass(\"Enter ACCESS_TOKEN for GitHub: \")\n",
    "\n",
    "# Load and chunk contents of the github repo\n",
    "loader = GithubFileLoader(\n",
    "    repo=\"ameliarogerscodes/TC-Examples\",  # the repo name\n",
    "    branch=\"main\",  # the branch name\n",
    "    # access_token=ACCESS_TOKEN, # delete/comment out this argument if you've set the access token as an env var.\n",
    "    github_api_url=\"https://api.github.com\",\n",
    "    # parser=LanguageParser(language=Language.PYTHON, parser_threshold=200),\n",
    "    file_filter=lambda file_path: file_path.endswith(\n",
    "        \".py\"\n",
    "    ),  # load all python files.\n",
    ")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4df20-f761-4288-b10a-574e3a2a21f4",
   "metadata": {},
   "source": [
    "* [ ] test documents content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ad2951-9597-42c1-b399-1f7caa8e9949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'CircuitBreaker/CircuitBreaker.py', 'sha': 'fcfed0fc14e5ae96bf700bf02546ddd55f7a4b8a', 'source': 'https://api.github.com/ameliarogerscodes/TC-Examples/blob/main/CircuitBreaker/CircuitBreaker.py'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb1b2a-4c2a-49f7-beae-e5200e0eee85",
   "metadata": {},
   "source": [
    "* [ ] map metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d2c29e-4580-4232-b678-8db2d4028644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Step 1: Load the JSON metadata from a file (adjust path accordingly)\n",
    "with open('./repo_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    json_metadata_list = json.load(f)\n",
    "\n",
    "# The sample JSON will be like a list of dicts, for example:\n",
    "# [\n",
    "#   {\"path\": \"src/pybreaker.py\", \"type\": \"source\", \"tech-credit\": \"Circuit Breaker\", \"tech_credit_description\": \"good design\"},\n",
    "#   {\"path\": \"test/unitest_pybreaker.py\", \"type\": \"test\", \"tech-credit\": \"Circuit Breaker\", \"tech_credit_description\": \"good design\"}\n",
    "# ]\n",
    "\n",
    "# Step 2: Create a dictionary mapping from path to metadata (excluding 'path' key)\n",
    "metadata_map = {\n",
    "    entry['path']: {k: v for k, v in entry.items() if k != 'path'}\n",
    "    for entry in json_metadata_list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abeffb-07c5-4036-95ef-320590c19b61",
   "metadata": {},
   "source": [
    "* [X] use code splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a26421b-1478-4354-a169-62389fdd8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use code-splitter \n",
    "# https://pypi.org/project/code-splitter/\n",
    "python_splitter = TiktokenSplitter(Language.Python, max_size=100)\n",
    "all_splits = [\n",
    "    Document(\n",
    "        page_content=splits.text,\n",
    "        metadata=metadata_map.get(doc.metadata.get('path'), {})\n",
    "    )\n",
    "    for doc in documents \n",
    "    for splits in python_splitter.split(doc.page_content.encode(\"utf-8\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280decb5-9f05-4303-9964-b10df988ab5c",
   "metadata": {},
   "source": [
    "* [ ] print page_content and metadata for a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f9958ae-a050-4d27-b065-c6d9c63ec640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class CircuitBreakerState:\n",
      "    def __init__(self, breaker, name):\n",
      "        self._breaker = breaker\n",
      "        self._name = name\n",
      "\n",
      "    @property\n",
      "    def name(self):\n",
      "        return self._name\n",
      "{'type': 'source', 'tech_credit': 'Circuit Breaker', 'tech_credit_description': 'Enhance system resilience by dynamically detecting service failures and preventing cascading issues, especially in distributed systems.'}\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[3].page_content)\n",
    "print(all_splits[4].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ffe88-73d0-4bc0-9b33-299d1139db49",
   "metadata": {},
   "source": [
    "* [ ] load, split and embed documents into vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfc96a-85ce-4a0b-9da0-4b7d00c46e23",
   "metadata": {},
   "source": [
    "* [x] index chunks for code vector db\n",
    "* [ ] index chunks for documentation vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57fa4981-55e9-40d1-9df3-b1891d549073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "code_embed_index = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f39c77-6a6d-4979-a565-3bdc65236170",
   "metadata": {},
   "source": [
    "* [ ] load, chunk, split and embed documents about technical credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b926570a-74c5-4b24-8b75-a830ab290d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "bs4_strainer = bs4.SoupStrainer(\n",
    "    class_=(\"article-header__section\", \"article-header__topic-and-issue-section\",\n",
    "            \"article-header article-header__title\", \"article-header__subtitle\",\n",
    "        \t\"article-header__meta\",\n",
    "        \t\"article-table-of-contents\",\n",
    "        \t\"article-contents\",\n",
    "        \t\"article-footer\")\n",
    ")\n",
    "\n",
    "doc_loader = WebBaseLoader(\n",
    "    web_paths=(\"https://cacm.acm.org/opinion/technical-credit/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4_strainer\n",
    "    ),\n",
    ")\n",
    "\n",
    "text_documents = doc_loader.load()\n",
    "# recurisive splitter , 7 , all splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57093c26-c49c-454b-964d-985d99c027e1",
   "metadata": {},
   "source": [
    "* [ ] test the web page document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "775b323a-607b-478c-aeec-ca538dd21511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 14484\n",
      "Opinion\n",
      "\n",
      "Computing Profession \n",
      "\n",
      "\n",
      "Balancing initial investment and long-term results in the software development process.\n",
      "\n",
      "\n",
      "\t\t\t\tBy Ian Gorton, Alessio Bucaioni, and Patrizio Pelliccione \n",
      "\n",
      "Posted Dec 26 2024 \n",
      "\n",
      "\n",
      "\n",
      "What Is Technical Credit?\n",
      "Technical Credit in Practice\n",
      "A Research Agenda for Technical Credit\n",
      "Conclusion\n",
      "References\n",
      "Footnotes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technical debt (TD) is an established concept in software engineering encompassing an unavoidable side effect of software development.3 It arises due to tight s\n"
     ]
    }
   ],
   "source": [
    "assert len(text_documents) == 1\n",
    "print(f\"Total characters: {len(text_documents[0].page_content)}\")\n",
    "print(text_documents[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2dcd6c-3469-4211-95bd-eadd65f86743",
   "metadata": {},
   "source": [
    "* [ ] split the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1963b0b9-1ac0-44d4-8c7e-8246eb5e3979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split article into 20 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "text_splits = text_splitter.split_documents(text_documents)\n",
    "\n",
    "print(f\"Split article into {len(text_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8341841c-23d3-40c8-83d0-b2187ac2c44a",
   "metadata": {},
   "source": [
    "* [ ] embed the documents into vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd11df3-bfa5-418d-bd78-60ad0497b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = document_store.add_documents(documents=text_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6178740-773d-432d-a533-45e2a4a21b4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RAG System Part\n",
    "## Customize Prompt\n",
    "## Define nodes and graphs in the rag system\n",
    "1. [X] retrieve code and metadata\n",
    "2. [X] retrieve academic documents\n",
    "3. [X] send message to LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93143ad-64df-4240-882f-e0b1d1d9b171",
   "metadata": {},
   "source": [
    "* [ ] design prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5bf3a43-d68d-4415-bb28-c321c42870b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for question-answering\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import textwrap\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an assistant for identifying technical credit. Use the following pieces \\\n",
    "                of retrieved context to answer the question. If you don't know the answer, just \\\n",
    "                say that you don't know. Use three sentences maximum and keep the answer concise.\"),\n",
    "    (\"user\", textwrap.dedent(\"\"\"\\\n",
    "                Here is the descirption for the tech credit:\n",
    "                {tech_credit}\n",
    "\n",
    "                Some documentation about tech credit:\n",
    "                {context_doc}\n",
    "\n",
    "                Here is an example code for that tech credit:\n",
    "                {context_code}\n",
    "\n",
    "                Here is the code from user:\n",
    "                {code}\n",
    "\n",
    "                Question: {question}\n",
    "                Answer:\n",
    "                \"\"\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4a1aa-75cf-43fd-93de-90825266fa11",
   "metadata": {},
   "source": [
    "* [ ] collect metadata from code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba89a7a6-3c3f-4969-bdff-5cc6627d330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_unique_pairs(documents):\n",
    "    \"\"\"\n",
    "    Collect unique concatenated 'tech_credit: description' strings from document metadata.\n",
    "\n",
    "    Args:\n",
    "        documents (list[dict]): A list of Document objects, each with a 'metadata' field.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of unique 'tech_credit: description' strings.\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "\n",
    "    for doc in documents:\n",
    "        metadata = doc.metadata\n",
    "        credit = metadata.get(\"tech_credit\")\n",
    "        description = metadata.get(\"tech_credit_description\")\n",
    "        if credit and description:\n",
    "            combined = f\"{credit}: {description}\"\n",
    "            seen.add(combined)\n",
    "\n",
    "    return list(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad89e54e-0483-47d8-bda7-45e4ecec352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context_code: List[Document]\n",
    "    context_doc: List[Document]\n",
    "    code: str # user code\n",
    "    tech_credit: List[str] # metadata of tech_credit and description fetched from code db\n",
    "    answer: str\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_codes = vector_store.search(\n",
    "        state[\"code\"], search_type=\"similarity_score_threshold\", \n",
    "        score_threshold=0.5 # set a threshold for similarity on code\n",
    "    )\n",
    "    retrieved_metadata = collect_unique_pairs(retrieved_codes)\n",
    "    return {\"context_code\": retrieved_codes, \"tech_credit\": retrieved_metadata}\n",
    "\n",
    "def retrieve_doc(state: State):\n",
    "    retrieved_doc = document_store.similarity_search(state[\"question\"])\n",
    "    return {\"context_doc\": retrieved_doc}\n",
    "    \n",
    "def generate(state: State):\n",
    "    code_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context_code\"])\n",
    "    tech_credit_content = \"\\n\".join(state[\"tech_credit\"])\n",
    "    # print(\"Tech credit description: \", tech_credit_content)\n",
    "    doc_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context_doc\"])\n",
    "    #print(docs_content)\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"code\": state[\"code\"], \n",
    "                              \"context_code\": code_content, \"tech_credit\": tech_credit_content, \n",
    "                              \"context_doc\": doc_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "    # return {\"answer\": \"No answer\"}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_node(retrieve_doc)\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(START, \"retrieve_doc\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c890ef-9f4b-4f62-929b-64bc5b33b4c4",
   "metadata": {},
   "source": [
    "# Ask Question Part\n",
    "## Circuit Breaker\n",
    "## MVC model\n",
    "## Iterator pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb72313-9804-4db0-a3fe-ccd2841f9c6a",
   "metadata": {},
   "source": [
    "* [ ] Ask questions and test RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c34b9354-59f4-459b-aba2-2d0ca037ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, this is a technical credit implementation. The three states of the Circuit Breaker represent different stages of system resilience: \n",
      "\n",
      "1. CLOSED state: The service is functioning normally and allowing requests to pass through.\n",
      "2. OPEN state: When failures exceed a threshold, the circuit \"breaks\" and prevents further requests to avoid cascading failures.\n",
      "3. HALF_OPEN state: A transitional state where the system tentatively allows a few requests to test if the underlying service has recovered.\n",
      "\n",
      "This pattern helps prevent system overload and provides a mechanism for graceful degradation during service disruptions, which aligns with the technical credit description of enhancing system resilience in distributed systems.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \n",
    "                         \"Tell me if the following is a tech credit and what do these 3 states do?\",\n",
    "\"code\": \"\"\"class CircuitBreakerState(Enum):\n",
    "    CLOSED = 'CLOSED'\n",
    "    OPEN = 'OPEN'\n",
    "    HALF_OPEN = 'HALF_OPEN'\n",
    "\"\"\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9555891c-8078-4a9e-9267-b85aa12ef207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, this is a technical credit implementation of a Circuit Breaker pattern. The three states represent different stages of service resilience:\n",
      "\n",
      "1. ON (CLOSED): Normal operation where the service is functioning correctly and requests are allowed.\n",
      "2. OFF (OPEN): Service is temporarily disabled after repeated failures to prevent further system damage.\n",
      "3. HALF_ON (HALF_OPEN): A transitional state where the system cautiously allows a few requests to test if the underlying issue has been resolved.\n",
      "\n",
      "These states help manage system resilience by dynamically detecting and responding to service failures, preventing cascading issues in distributed systems.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Tell me if the following is a tech credit and what do these 3 states do?\",\n",
    "\"code\": \"\"\"class myBreaker(Enum):\n",
    "    ON = 'CLOSED'\n",
    "    OFF = 'OPEN'\n",
    "    HALF_ON = 'HALF_OPEN'\"\"\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91980572-6736-4cd0-894d-d42f372e0bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, this is an implementation of the Model-View-Controller (MVC) technical credit pattern. The code separates concerns into three distinct components: UserModel (data and business logic), UserView (user interface), and the implied UserController (not shown, but suggested by the MVC structure). This approach promotes modularity, makes the code more maintainable, and allows independent development and testing of each component, which aligns perfectly with the MVC technical credit description provided earlier.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Tell me if the following is a tech credit?\",\n",
    "\"code\": \"\"\"class UserModel:\n",
    "    def __init__(self):\n",
    "        self.users = []\n",
    "    \n",
    "    def add_user(self, name, age):\n",
    "        user = {\"name\": name, \"age\": age}\n",
    "        self.users.append(user)\n",
    "        return user\n",
    "    \n",
    "    def get_all_users(self):\n",
    "        return self.users\n",
    "\n",
    "class UserView:\n",
    "    def show_users(self, users):\n",
    "        print(\"\\n=== User List ===\")\n",
    "        if not users:\n",
    "            print(\"No user\")\n",
    "        else:\n",
    "            for i, user in enumerate(users, 1):\n",
    "                print(f\"{i}. Name: {user['name']}, Age: {user['age']}\")\n",
    "    \n",
    "    def show_menu(self):\n",
    "        print(\"\\n=== Menu ===\")\n",
    "        print(\"1. Add user\")\n",
    "        print(\"2. List all users\")\n",
    "        print(\"3. Exit\")\n",
    "        return input(\"Your option: \")\n",
    "    \n",
    "    def get_user_input(self):\n",
    "        name = input(\"Name: \")\n",
    "        age = input(\"Age: \")\n",
    "        return name, age\n",
    "    \n",
    "    def show_message(self, message):\n",
    "        print(message)\"\"\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e17b8816-0600-47bb-8371-d010eaba2ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context about technical credit, the simple \"Hello, world!\" program does not represent technical credit. Technical credit involves strategic design decisions that provide long-term benefits, such as creating abstraction layers, implementing circuit breakers, or developing reference architectures. This basic print statement does not demonstrate any characteristics of technical credit that would ease future modifications or provide systemic advantages.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Tell me if the following is a tech credit?\",\n",
    "\"code\": \"\"\"# This program prints Hello, world!\n",
    "\n",
    "print('Hello, world!')\"\"\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe566a7-f5bf-4417-a90a-84ad342cf435",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Roadmap:\n",
    "\n",
    "1. Use a text embedding model.\n",
    "   + [X] gemini text-embedding-004\n",
    "2. Code splitter may not work properly.\n",
    "   + [X] change to code-splitter that works better.\n",
    "3. [X] Switch in memory vector storage to a vector database\n",
    "   + [X] code vector database with additional metadata for tech credit\n",
    "   + [X] document vector database with academic context about tech credit\n",
    "4. [ ] Load more standard example codes for tech credit (~20 more examples)\n",
    "5. [ ] Load more documents (academic contexts) for technical credit (3~5 related academic paper)\n",
    "6. [ ] Allow user to ask about a repository, instead of small snippets of codes\n",
    "   * [ ] load, chunk, split, embed and vectorize a repo\n",
    "   * [ ] similarity search and filter user code by similarity score compared with example code\n",
    "   * [ ] batch process to LLM\n",
    "   * [ ] organize response and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042c9c8-041f-4a3d-aacd-c5415b2f1fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ec0f76-970a-47cd-aa1e-0a2e1a6ad92f",
   "metadata": {},
   "source": [
    "# Preview from LangChain\n",
    "\n",
    "## Step by step code\n",
    "\n",
    "1. get LangSmith API Key from environment\n",
    "2. set up anthropic key for chat model\n",
    "3. set up embedding model for embeddings\n",
    "4. select vector database\n",
    "5. set up document loader and split up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8825c3-e6e4-4541-aa62-fc862ba42bc6",
   "metadata": {},
   "source": [
    "## Tutorials\n",
    "LangChain RAG tutorial document\n",
    "Part 1\n",
    "https://python.langchain.com/docs/tutorials/rag\n",
    "\n",
    "Part 2\n",
    "extends the implementation to accommodate conversation-style interactions and\n",
    "multi-step retrieval processes.\n",
    "https://python.langchain.com/docs/tutorials/qa_chat_history/\n",
    "\n",
    "LangChain document loader for GitHub Repo\n",
    "https://python.langchain.com/docs/integrations/document_loaders/github/\n",
    "\n",
    "LangChain document loader for Git Repository\n",
    "https://python.langchain.com/docs/integrations/document_loaders/git/\n",
    "\n",
    "LangChain document loader for Source Code (e.g. Python)\n",
    "https://python.langchain.com/docs/integrations/document_loaders/source_code/\n",
    "\n",
    "LangSmith evaluation for a chatbot\n",
    "https://docs.smith.langchain.com/evaluation/tutorials/evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00262b7-72d9-4472-bdcb-f1a85e3321eb",
   "metadata": {},
   "source": [
    "* [X] set up LangSmith key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79f4383-61f6-41d8-9536-0873e426f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for LangSmith to enable tracing:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith to enable tracing: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36908430-f05f-4d6f-ae67-cafb09ed39db",
   "metadata": {},
   "source": [
    "* [X] set up Anthropic key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac315b7b-3b72-4f20-a641-9b2b498a7100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for Anthropic:  ········\n"
     ]
    }
   ],
   "source": [
    "if not os.environ.get(\"ANTHROPIC_API_KEY\"):\n",
    "  os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter API key for Anthropic: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"claude-3-5-haiku-latest\", model_provider=\"anthropic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032cc2a-ae18-40bf-86aa-08270b25fc32",
   "metadata": {},
   "source": [
    "* [X] set up Google gemini as embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b61b89-8f2b-4d42-b768-cba7f2ce3a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for Google Gemini:  ········\n"
     ]
    }
   ],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7a684-56c6-40e1-8a64-b86089a6e12c",
   "metadata": {},
   "source": [
    "* [X] set up vector database \n",
    "\n",
    "# Choosing database\n",
    "\n",
    "## Candidates\n",
    "\n",
    "1. cassandra\n",
    "2. open search https://opensearch.org/platform/os-search/vector-database/\n",
    "3. Pinecone\n",
    "4. MongoDB\n",
    "5. PostgreSQL\n",
    "6. [X] Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5954c2e3-3c86-41f1-9ce2-d76e5fb88ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"python_tech_credit\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "document_store = Chroma(\n",
    "    collection_name=\"document_tech_credit\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf0591-3020-489b-9563-00a12e3a20bb",
   "metadata": {},
   "source": [
    "* [ ] Import and load a GitHub Repo as a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ee1cb4-7571-4e12-a190-58e53b4d6be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter ACCESS_TOKEN for GitHub:  ········\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import GithubFileLoader\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from code_splitter import Language, TiktokenSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "if not os.environ.get(\"GITHUB_PERSONAL_ACCESS_TOKEN\"):\n",
    "   os.environ[\"GITHUB_PERSONAL_ACCESS_TOKEN\"] = getpass.getpass(\"Enter ACCESS_TOKEN for GitHub: \")\n",
    "\n",
    "# Load and chunk contents of the github repo\n",
    "loader = GithubFileLoader(\n",
    "    repo=\"danielfm/pybreaker\",  # the repo name\n",
    "    branch=\"main\",  # the branch name\n",
    "    # access_token=ACCESS_TOKEN, # delete/comment out this argument if you've set the access token as an env var.\n",
    "    github_api_url=\"https://api.github.com\",\n",
    "    # parser=LanguageParser(language=Language.PYTHON, parser_threshold=200),\n",
    "    file_filter=lambda file_path: file_path.endswith(\n",
    "        \".py\"\n",
    "    ),  # load all python files.\n",
    ")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4df20-f761-4288-b10a-574e3a2a21f4",
   "metadata": {},
   "source": [
    "* [ ] test documents content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ad2951-9597-42c1-b399-1f7caa8e9949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'src/pybreaker/__init__.py', 'sha': 'c7fa085ff4bd506de069f999bbcdeada74aff4bd', 'source': 'https://api.github.com/danielfm/pybreaker/blob/main/src/pybreaker/__init__.py'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb1b2a-4c2a-49f7-beae-e5200e0eee85",
   "metadata": {},
   "source": [
    "* [ ] map metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d2c29e-4580-4232-b678-8db2d4028644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Step 1: Load the JSON metadata from a file (adjust path accordingly)\n",
    "with open('./repo_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    json_metadata_list = json.load(f)\n",
    "\n",
    "# The sample JSON will be like a list of dicts, for example:\n",
    "# [\n",
    "#   {\"path\": \"src/pybreaker.py\", \"type\": \"source\", \"tech-credit\": \"Circuit Breaker\", \"tech_credit_description\": \"good design\"},\n",
    "#   {\"path\": \"test/unitest_pybreaker.py\", \"type\": \"test\", \"tech-credit\": \"Circuit Breaker\", \"tech_credit_description\": \"good design\"}\n",
    "# ]\n",
    "\n",
    "# Step 2: Create a dictionary mapping from path to metadata (excluding 'path' key)\n",
    "metadata_map = {\n",
    "    entry['path']: {k: v for k, v in entry.items() if k != 'path'}\n",
    "    for entry in json_metadata_list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abeffb-07c5-4036-95ef-320590c19b61",
   "metadata": {},
   "source": [
    "* [X] use code splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a26421b-1478-4354-a169-62389fdd8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use code-splitter \n",
    "# https://pypi.org/project/code-splitter/\n",
    "python_splitter = TiktokenSplitter(Language.Python, max_size=100)\n",
    "all_splits = [\n",
    "    Document(\n",
    "        page_content=splits.text,\n",
    "        metadata=metadata_map.get(doc.metadata.get('path'), {})\n",
    "    )\n",
    "    for doc in documents \n",
    "    for splits in python_splitter.split(doc.page_content.encode(\"utf-8\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280decb5-9f05-4303-9964-b10df988ab5c",
   "metadata": {},
   "source": [
    "* [ ] print page_content and metadata for a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f9958ae-a050-4d27-b065-c6d9c63ec640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__all__ = (\n",
      "    \"CircuitBreaker\",\n",
      "    \"CircuitBreakerListener\",\n",
      "    \"CircuitBreakerError\",\n",
      "    \"CircuitMemoryStorage\",\n",
      "    \"CircuitRedisStorage\",\n",
      "    \"STATE_OPEN\",\n",
      "    \"STATE_CLOSED\",\n",
      "    \"STATE_HALF_OPEN\",\n",
      ")\n",
      "\n",
      "STATE_OPEN = \"open\"\n",
      "STATE_CLOSED = \"closed\"\n",
      "STATE_HALF_OPEN = \"half-open\"\n",
      "\n",
      "T = TypeVar(\"T\")\n",
      "ExceptionType = TypeVar(\"ExceptionType\", bound=BaseException)\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[3].page_content)\n",
    "print(all_splits[4].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ffe88-73d0-4bc0-9b33-299d1139db49",
   "metadata": {},
   "source": [
    "* [ ] load, split and embed documents into vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfc96a-85ce-4a0b-9da0-4b7d00c46e23",
   "metadata": {},
   "source": [
    "* [x] index chunks for code vector db\n",
    "* [ ] index chunks for documentation vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa4981-55e9-40d1-9df3-b1891d549073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f39c77-6a6d-4979-a565-3bdc65236170",
   "metadata": {},
   "source": [
    "* [ ] load, chunk, split and embed documents about technical credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b926570a-74c5-4b24-8b75-a830ab290d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk contents of the blog\n",
    "doc_loader = WebBaseLoader(\n",
    "    web_paths=(\"https://cacm.acm.org/opinion/technical-credit/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=()\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# recurisive splitter , 7 , all splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93143ad-64df-4240-882f-e0b1d1d9b171",
   "metadata": {},
   "source": [
    "* [ ] design prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf3a43-d68d-4415-bb28-c321c42870b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for question-answering\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an assistant for identifying technical credit. Use the following pieces \\\n",
    "                of retrieved context to answer the question. If you don't know the answer, just \\\n",
    "                say that you don't know. Use three sentences maximum and keep the answer concise.\"),\n",
    "    (\"user\", \"\"\"Here is the descirption for the tech credit:\n",
    "                {tech_credit}\n",
    "\n",
    "                Some documentation about tech credit:\n",
    "                {context_doc}\n",
    "\n",
    "                Here is an example code for that tech credit:\n",
    "                {context_code}\n",
    "\n",
    "                Here is the code from user:\n",
    "                {code}\n",
    "\n",
    "                Question: {question}\n",
    "                Answer:\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4a1aa-75cf-43fd-93de-90825266fa11",
   "metadata": {},
   "source": [
    "* [ ] collect metadata from code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba89a7a6-3c3f-4969-bdff-5cc6627d330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_unique_pairs(documents):\n",
    "    \"\"\"\n",
    "    Collect unique concatenated 'tech_credit: description' strings from document metadata.\n",
    "\n",
    "    Args:\n",
    "        documents (list[dict]): A list of Document objects, each with a 'metadata' field.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of unique 'tech_credit: description' strings.\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "\n",
    "    for doc in documents:\n",
    "        metadata = doc.get(\"metadata\", {})\n",
    "        credit = metadata.get(\"tech_credit\")\n",
    "        description = metadata.get(\"tech_credit_description\")\n",
    "        if credit and description:\n",
    "            combined = f\"{credit}: {description}\"\n",
    "            seen.add(combined)\n",
    "\n",
    "    return list(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad89e54e-0483-47d8-bda7-45e4ecec352e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TypedDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Define state for application\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mState\u001b[39;00m(\u001b[43mTypedDict\u001b[49m):\n\u001b[32m      3\u001b[39m     question: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m      4\u001b[39m     context_code: List[Document]\n",
      "\u001b[31mNameError\u001b[39m: name 'TypedDict' is not defined"
     ]
    }
   ],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context_code: List[Document]\n",
    "    context_doc: List[Document]\n",
    "    code: str # user code\n",
    "    tech_credit: List[str] # metadata of tech_credit and description fetched from code db\n",
    "    answer: str\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_codes = vector_store.similarity_search(state[\"code\"])\n",
    "    retrieved_metadata = collect_unique_pairs(retrieved_codes)\n",
    "    return {\"context_code\": retrieved_codes, \"tech_credit\": retrieved_metad}\n",
    "\n",
    "def retrieve_doc(state: State):\n",
    "    retrieved_doc = document_store.similarity_search(state[\"question\"])\n",
    "    return {\"context_doc\": retrieved_doc}\n",
    "    \n",
    "def generate(state: State):\n",
    "    code_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context_code\"])\n",
    "    tech_credit_content = \"\\n\".join(state[\"tech_credit\"])\n",
    "    doc_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context_doc\"])\n",
    "    #print(docs_content)\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"code\": state[\"code\"], \n",
    "                              \"context_code\": code_content, \"tech_credit\": tech_credit_content, \n",
    "                              \"context_doc\": doc_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_node(retrieve_doc)\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(START, \"retrieve_doc\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb72313-9804-4db0-a3fe-ccd2841f9c6a",
   "metadata": {},
   "source": [
    "* [ ] Ask questions and test RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a01007dd-d4fa-45ee-a077-3d7ae95e0d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CircuitBreaker is a design pattern that prevents a system from repeatedly trying operations that are likely to fail. In its \"closed\" state, the circuit breaker executes operations normally, tracking failures and tripping (opening the circuit) when a failure threshold is exceeded. When the circuit is open, it prevents further attempts to execute the operation, helping to protect the system from repeated failures.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Explain the Class CircuitBreaker\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c34b9354-59f4-459b-aba2-2d0ca037ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, these are standard states of a circuit breaker implementation. CLOSED represents the normal operating state where requests are allowed. OPEN represents the state where requests are blocked due to failures, and HALF_OPEN is a transitional state where a single request is allowed to test if the system has recovered.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Tell me if the following is a component of circuit breaker and what does these three state do?\",\n",
    "\"code\": \"\"\"\n",
    "class CircuitBreakerState(Enum):\n",
    "    CLOSED = 'CLOSED'\n",
    "    OPEN = 'OPEN'\n",
    "    HALF_OPEN = 'HALF_OPEN'\n",
    "\"\"\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257d1b73-ca66-4235-ad0c-504ab6625e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, this is a component of the circuit breaker pattern defining the possible states of a circuit breaker. The states represent different conditions of the circuit breaker: CLOSED means the circuit is functioning normally and allowing requests, OPEN indicates the circuit is blocked and preventing requests after repeated failures, and HALF_OPEN represents a transitional state where the circuit allows a limited number of requests to test if the underlying issue has been resolved.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"\"\"Tell me if the following is a component of circuit breaker and what does \n",
    "these three state do?\n",
    "class CircuitBreakerState(Enum):\n",
    "    CLOSED = 'CLOSED'\n",
    "    OPEN = 'OPEN'\n",
    "    HALF_OPEN = 'HALF_OPEN'\n",
    "\"\"\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe566a7-f5bf-4417-a90a-84ad342cf435",
   "metadata": {},
   "source": [
    "## Known problems:\n",
    "\n",
    "1. Text embedding model by gemini may not be optimal.\n",
    "2. Code splitter may not work properly.\n",
    "   + [X] change to code-splitter that works better.\n",
    "4. Switch in memory vector storage to a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042c9c8-041f-4a3d-aacd-c5415b2f1fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

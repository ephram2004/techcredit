{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ec0f76-970a-47cd-aa1e-0a2e1a6ad92f",
   "metadata": {
    "id": "b1ec0f76-970a-47cd-aa1e-0a2e1a6ad92f"
   },
   "source": [
    "# LangChain RAG system for detecting Tech Credit\n",
    "\n",
    "## Step by step code\n",
    "\n",
    "1. get LangSmith API Key from environment\n",
    "2. set up anthropic key for chat model\n",
    "3. set up embedding model for embeddings\n",
    "4. select vector database\n",
    "5. set up document loader and split up\n",
    "\n",
    "## Set up API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8825c3-e6e4-4541-aa62-fc862ba42bc6",
   "metadata": {
    "id": "dd8825c3-e6e4-4541-aa62-fc862ba42bc6"
   },
   "source": [
    "## Tutorials\n",
    "LangChain RAG tutorial document\n",
    "Part 1\n",
    "https://python.langchain.com/docs/tutorials/rag\n",
    "\n",
    "Part 2\n",
    "extends the implementation to accommodate conversation-style interactions and\n",
    "multi-step retrieval processes.\n",
    "https://python.langchain.com/docs/tutorials/qa_chat_history/\n",
    "\n",
    "LangChain document loader for GitHub Repo\n",
    "https://python.langchain.com/docs/integrations/document_loaders/github/\n",
    "\n",
    "LangChain document loader for Git Repository\n",
    "https://python.langchain.com/docs/integrations/document_loaders/git/\n",
    "\n",
    "LangChain document loader for Source Code (e.g. Python)\n",
    "https://python.langchain.com/docs/integrations/document_loaders/source_code/\n",
    "\n",
    "LangSmith evaluation for a chatbot\n",
    "https://docs.smith.langchain.com/evaluation/tutorials/evaluation\n",
    "\n",
    "LangSmith evaluation for a rag\n",
    "https://docs.smith.langchain.com/evaluation/tutorials/rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00262b7-72d9-4472-bdcb-f1a85e3321eb",
   "metadata": {
    "id": "f00262b7-72d9-4472-bdcb-f1a85e3321eb"
   },
   "source": [
    "* [X] set up LangSmith key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df6d3b0c-86ee-4aff-b9cd-8ea7e6b8482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dotenv to store secrets\n",
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79f4383-61f6-41d8-9536-0873e426f630",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749173837777,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "f79f4383-61f6-41d8-9536-0873e426f630"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "  os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "  os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith to enable tracing: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36908430-f05f-4d6f-ae67-cafb09ed39db",
   "metadata": {
    "id": "36908430-f05f-4d6f-ae67-cafb09ed39db"
   },
   "source": [
    "* [X] set up Anthropic key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac315b7b-3b72-4f20-a641-9b2b498a7100",
   "metadata": {
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1749173838993,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "ac315b7b-3b72-4f20-a641-9b2b498a7100"
   },
   "outputs": [],
   "source": [
    "if not os.environ.get(\"CLAUDE_API_KEY\"):\n",
    "  os.environ[\"CLAUDE_API_KEY\"] = getpass.getpass(\"Enter API key for Anthropic: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "claude_llm = init_chat_model(\"claude-sonnet-4-20250514\", model_provider=\"anthropic\")\n",
    "claude_llm_haiku = init_chat_model(\"claude-3-5-haiku-latest\", model_provider=\"anthropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7toq03rolCnr",
   "metadata": {
    "executionInfo": {
     "elapsed": 1231,
     "status": "ok",
     "timestamp": 1749173840223,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "7toq03rolCnr"
   },
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "openai_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032cc2a-ae18-40bf-86aa-08270b25fc32",
   "metadata": {
    "id": "7032cc2a-ae18-40bf-86aa-08270b25fc32"
   },
   "source": [
    "* [X] set up Google gemini as embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "278e39ad-8e1c-44eb-9502-0e7a84d36964",
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1749173840742,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "278e39ad-8e1c-44eb-9502-0e7a84d36964"
   },
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "   os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Fi70rWLh2FgV",
   "metadata": {
    "executionInfo": {
     "elapsed": 21571,
     "status": "ok",
     "timestamp": 1749173862316,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "Fi70rWLh2FgV"
   },
   "outputs": [],
   "source": [
    "if not os.environ.get(\"HF_TOKEN\"):\n",
    "  os.environ[\"HF_TOKEN\"] = getpass.getpass(\"Enter API key for HuggingFace Hub Token: \")\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "hugging_face_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaRDC0-44Q4S",
   "metadata": {
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1749173862726,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "aaRDC0-44Q4S"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7a684-56c6-40e1-8a64-b86089a6e12c",
   "metadata": {
    "id": "fad7a684-56c6-40e1-8a64-b86089a6e12c"
   },
   "source": [
    "* [X] set up vector database\n",
    "\n",
    "# Choosing database\n",
    "\n",
    "Load, chunk, split, embed and vectorize code data and document data into database\n",
    "\n",
    "## Candidates\n",
    "\n",
    "1. cassandra\n",
    "2. open search https://opensearch.org/platform/os-search/vector-database/\n",
    "3. Pinecone\n",
    "4. MongoDB\n",
    "5. PostgreSQL\n",
    "6. [X] Chroma, locally hosted with sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5954c2e3-3c86-41f1-9ce2-d76e5fb88ec5",
   "metadata": {
    "executionInfo": {
     "elapsed": 1556,
     "status": "ok",
     "timestamp": 1749173864287,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "5954c2e3-3c86-41f1-9ce2-d76e5fb88ec5"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# huggingface_store = Chroma(\n",
    "#     collection_name=\"hf_python_tech_credit\",\n",
    "#     embedding_function=hugging_face_embeddings,\n",
    "#     persist_directory=\"./chroma_langchain_db\",\n",
    "# )\n",
    "\n",
    "# openai_store = Chroma(\n",
    "#     collection_name=\"openai_python_tech_credit\",\n",
    "#     embedding_function=openai_embeddings,\n",
    "#     persist_directory=\"./chroma_langchain_db\",\n",
    "# )\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"python_tech_credit\",\n",
    "    embedding_function=gemini_embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "document_store = Chroma(\n",
    "    collection_name=\"document_tech_credit\",\n",
    "    embedding_function=gemini_embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf0591-3020-489b-9563-00a12e3a20bb",
   "metadata": {
    "id": "2ebf0591-3020-489b-9563-00a12e3a20bb"
   },
   "source": [
    "* [ ] Import and load a GitHub Repo as a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8ee1cb4-7571-4e12-a190-58e53b4d6be5",
   "metadata": {
    "executionInfo": {
     "elapsed": 3303,
     "status": "ok",
     "timestamp": 1749173867561,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "f8ee1cb4-7571-4e12-a190-58e53b4d6be5"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import GithubFileLoader\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "from code_splitter import Language, TiktokenSplitter\n",
    "\n",
    "if not os.environ.get(\"GITHUB_PERSONAL_ACCESS_TOKEN\"):\n",
    "   os.environ[\"GITHUB_PERSONAL_ACCESS_TOKEN\"] = getpass.getpass(\"Enter ACCESS_TOKEN for GitHub: \")\n",
    "\n",
    "# Load and chunk contents of the github repo\n",
    "loader = GithubFileLoader(\n",
    "    repo=\"ameliarogerscodes/TC-Examples\",  # the repo name\n",
    "    branch=\"main\",  # the branch name\n",
    "    # access_token=ACCESS_TOKEN, # delete/comment out this argument if you've set the access token as an env var.\n",
    "    github_api_url=\"https://api.github.com\",\n",
    "    # parser=LanguageParser(language=Language.PYTHON, parser_threshold=200),\n",
    "    file_filter=lambda file_path: file_path.endswith(\n",
    "        \".py\"\n",
    "    ),  # load all python files.\n",
    ")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4df20-f761-4288-b10a-574e3a2a21f4",
   "metadata": {
    "id": "53f4df20-f761-4288-b10a-574e3a2a21f4"
   },
   "source": [
    "* [ ] test documents content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23ad2951-9597-42c1-b399-1f7caa8e9949",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1749173867568,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "23ad2951-9597-42c1-b399-1f7caa8e9949",
    "outputId": "085ab75f-6ba7-4b27-d51d-bc6439542bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'MVC/view.py', 'sha': '906c1ec1fe1d4d79a7e8b9fbdf80ab20e17236a0', 'source': 'https://api.github.com/ameliarogerscodes/TC-Examples/blob/main/MVC/view.py'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[7].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb1b2a-4c2a-49f7-beae-e5200e0eee85",
   "metadata": {
    "id": "20eb1b2a-4c2a-49f7-beae-e5200e0eee85"
   },
   "source": [
    "* [ ] map metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0d2c29e-4580-4232-b678-8db2d4028644",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1749173867586,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "c0d2c29e-4580-4232-b678-8db2d4028644"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Step 1: Load the JSON metadata from a file (adjust path accordingly)\n",
    "with open('./repo_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    json_metadata_list = json.load(f)\n",
    "\n",
    "# The sample JSON will be like a list of dicts, for example:\n",
    "# [\n",
    "#   {\"path\": \"src/pybreaker.py\", \"type\": \"source\", \"tech-credit\": \"Circuit Breaker\", \"tech_credit_description\": \"good design\"},\n",
    "#   {\"path\": \"test/unitest_pybreaker.py\", \"type\": \"test\", \"tech-credit\": \"Circuit Breaker\", \"tech_credit_description\": \"good design\"}\n",
    "# ]\n",
    "\n",
    "# Step 2: Create a dictionary mapping from path to metadata (excluding 'path' key)\n",
    "metadata_map = {\n",
    "    entry['path']: {k: v for k, v in entry.items() if k != 'path'}\n",
    "    for entry in json_metadata_list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abeffb-07c5-4036-95ef-320590c19b61",
   "metadata": {
    "id": "95abeffb-07c5-4036-95ef-320590c19b61"
   },
   "source": [
    "* [X] use code splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a26421b-1478-4354-a169-62389fdd8d60",
   "metadata": {
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1749173867787,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "0a26421b-1478-4354-a169-62389fdd8d60"
   },
   "outputs": [],
   "source": [
    "# use code-splitter\n",
    "# https://pypi.org/project/code-splitter/\n",
    "python_splitter = TiktokenSplitter(Language.Python, max_size=200)\n",
    "\n",
    "all_splits = [\n",
    "    Document(\n",
    "        page_content=(\n",
    "            # \"# ===== code structure =====\\n\"\n",
    "            # + \"\\n\".join(f\"# {line}\" for line in splits.subtree.splitlines())\n",
    "            # + \"\\n\\n\"\n",
    "            splits.text\n",
    "        ),\n",
    "        metadata=metadata_map.get(doc.metadata.get('path'), {})\n",
    "    )\n",
    "    for doc in documents\n",
    "    for splits in python_splitter.split(doc.page_content.encode(\"utf-8\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280decb5-9f05-4303-9964-b10df988ab5c",
   "metadata": {
    "id": "280decb5-9f05-4303-9964-b10df988ab5c"
   },
   "source": [
    "* [ ] print page_content and metadata for a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f9958ae-a050-4d27-b065-c6d9c63ec640",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1749173867818,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "7f9958ae-a050-4d27-b065-c6d9c63ec640",
    "outputId": "5de335d9-2b67-46eb-e2fe-51c42785c1f7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ConcreteComponentA(Component):\n",
      "    \"\"\"\n",
      "    Each Concrete Component must implement the `accept` method in such a way\n",
      "    that it calls the visitor's method corresponding to the component's class.\n",
      "    \"\"\"\n",
      "\n",
      "    def accept(self, visitor: Visitor) -> None:\n",
      "        \"\"\"\n",
      "        Note that we're calling `visitConcreteComponentA`, which matches the\n",
      "        current class name. This way we let the visitor know the class of the\n",
      "        component it works with.\n",
      "        \"\"\"\n",
      "\n",
      "        visitor.visit_concrete_component_a(self)\n",
      "\n",
      "    def exclusive_method_of_concrete_component_a(self) -> str:\n",
      "        \"\"\"\n",
      "        Concrete Components may have special methods that don't exist in their\n",
      "        base class or interface. The Visitor is still able to use these methods\n",
      "        since it's aware of the component's concrete class.\n",
      "        \"\"\"\n",
      "\n",
      "        return \"A\"\n",
      "{'type': 'source', 'tech_credit': 'Visitor Pattern', 'tech_credit_description': 'Represent an operation to be performed on instances of a set of classes. Visitor lets a new operation be defined without changing the classes of the elements on which it operates.'}\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[34].page_content)\n",
    "print(all_splits[34].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ffe88-73d0-4bc0-9b33-299d1139db49",
   "metadata": {
    "id": "996ffe88-73d0-4bc0-9b33-299d1139db49"
   },
   "source": [
    "* [ ] load, split and embed documents into vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfc96a-85ce-4a0b-9da0-4b7d00c46e23",
   "metadata": {
    "id": "77bfc96a-85ce-4a0b-9da0-4b7d00c46e23"
   },
   "source": [
    "* [x] index chunks for code vector db, DO NOT LOAD TWICE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57fa4981-55e9-40d1-9df3-b1891d549073",
   "metadata": {
    "executionInfo": {
     "elapsed": 36163,
     "status": "ok",
     "timestamp": 1749173903984,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "57fa4981-55e9-40d1-9df3-b1891d549073"
   },
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "code_embed_index_gemini = vector_store.add_documents(documents=all_splits)\n",
    "# code_embed_index_hf = huggingface_store.add_documents(documents=all_splits)\n",
    "# code_embed_index_openai = openai_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f39c77-6a6d-4979-a565-3bdc65236170",
   "metadata": {
    "id": "47f39c77-6a6d-4979-a565-3bdc65236170"
   },
   "source": [
    "* [ ] load, chunk, split and embed documents about technical credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b926570a-74c5-4b24-8b75-a830ab290d9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1749173904034,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "b926570a-74c5-4b24-8b75-a830ab290d9f",
    "outputId": "c6d7d200-2d88-4ccc-ed18-55e9d44c1289"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "bs4_strainer = bs4.SoupStrainer(\n",
    "    class_=(\"article-header__section\", \"article-header__topic-and-issue-section\",\n",
    "            \"article-header article-header__title\", \"article-header__subtitle\",\n",
    "        \t\"article-header__meta\",\n",
    "        \t\"article-table-of-contents\",\n",
    "        \t\"article-contents\",\n",
    "        \t\"article-footer\")\n",
    ")\n",
    "\n",
    "doc_loader = WebBaseLoader(\n",
    "    web_paths=(\"https://cacm.acm.org/opinion/technical-credit/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4_strainer\n",
    "    ),\n",
    ")\n",
    "\n",
    "text_documents = doc_loader.load()\n",
    "# recurisive splitter , 7 , all splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57093c26-c49c-454b-964d-985d99c027e1",
   "metadata": {
    "id": "57093c26-c49c-454b-964d-985d99c027e1"
   },
   "source": [
    "* [X] test the web page document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "775b323a-607b-478c-aeec-ca538dd21511",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1749173904055,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "775b323a-607b-478c-aeec-ca538dd21511",
    "outputId": "6bb60602-077a-44de-8872-2b5b79a8a735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 14484\n",
      "Opinion\n",
      "\n",
      "Computing Profession \n",
      "\n",
      "\n",
      "Balancing initial investment and long-term results in the software development process.\n",
      "\n",
      "\n",
      "\t\t\t\tBy Ian Gorton, Alessio Bucaioni, and Patrizio Pelliccione \n",
      "\n",
      "Posted Dec 26 2024 \n",
      "\n",
      "\n",
      "\n",
      "What Is Technical Credit?\n",
      "Technical Credit in Practice\n",
      "A Research Agenda for Technical Credit\n",
      "Conclusion\n",
      "References\n",
      "Footnotes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technical debt (TD) is an established concept in software engineering encompassing an unavoidable side effect of software development.3 It arises due to tight s\n"
     ]
    }
   ],
   "source": [
    "assert len(text_documents) == 1\n",
    "print(f\"Total characters: {len(text_documents[0].page_content)}\")\n",
    "print(text_documents[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2dcd6c-3469-4211-95bd-eadd65f86743",
   "metadata": {
    "id": "4a2dcd6c-3469-4211-95bd-eadd65f86743"
   },
   "source": [
    "* [ ] split the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1963b0b9-1ac0-44d4-8c7e-8246eb5e3979",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749173904065,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "1963b0b9-1ac0-44d4-8c7e-8246eb5e3979",
    "outputId": "7b6dff19-e42e-41ea-acd5-5aa2c8b74474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split article into 20 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "text_splits = text_splitter.split_documents(text_documents)\n",
    "\n",
    "print(f\"Split article into {len(text_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8341841c-23d3-40c8-83d0-b2187ac2c44a",
   "metadata": {
    "id": "8341841c-23d3-40c8-83d0-b2187ac2c44a"
   },
   "source": [
    "* [X] embed the documents into vector database, DO NOT LOAD TWICE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afd11df3-bfa5-418d-bd78-60ad0497b7b9",
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1749173904499,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "afd11df3-bfa5-418d-bd78-60ad0497b7b9"
   },
   "outputs": [],
   "source": [
    "document_ids = document_store.add_documents(documents=text_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6178740-773d-432d-a533-45e2a4a21b4e",
   "metadata": {
    "id": "a6178740-773d-432d-a533-45e2a4a21b4e"
   },
   "source": [
    "# RAG System Part\n",
    "## Customize Prompt\n",
    "## Define nodes and graphs in the rag system\n",
    "1. [X] retrieve code and metadata\n",
    "2. [X] retrieve academic documents\n",
    "3. [X] send message to LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93143ad-64df-4240-882f-e0b1d1d9b171",
   "metadata": {
    "id": "e93143ad-64df-4240-882f-e0b1d1d9b171"
   },
   "source": [
    "* [ ] design prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5bf3a43-d68d-4415-bb28-c321c42870b1",
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1749173904528,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "e5bf3a43-d68d-4415-bb28-c321c42870b1"
   },
   "outputs": [],
   "source": [
    "# Define prompt for question-answering\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from jinja2 import Environment, BaseLoader\n",
    "import textwrap\n",
    "\n",
    "jinja2_prompt = \"\"\"\\\n",
    "{% for part in parts %}\n",
    "Here is the No. {{ part.ordinal }} part of \n",
    "Descirption:\n",
    "{{ part.tech_credit }}\n",
    "\n",
    "Example code for that tech credit:\n",
    "{{ part.context_code }}\n",
    "\n",
    "Here is the code from user:\n",
    "{{ part.user_code }}\n",
    "{% endfor %}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_template = Environment(loader=BaseLoader).from_string(jinja2_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an assistant for identifying technical credit. Use the following pieces \\\n",
    "                of retrieved context to answer the question. The context are code snippets If you don't know the answer, just \\\n",
    "                say that you don't know. For each code snippet, use three sentences maximum and \\\n",
    "                keep the answer concise.\"),\n",
    "    (\"user\", textwrap.dedent(\"\"\"\\\n",
    "                Some documentation about tech credit:\n",
    "                {context_doc}\n",
    "\n",
    "                The following are snippets of codes that are most similar to example codes of\n",
    "                tech credits.\n",
    "                {rendered}\n",
    "\n",
    "                Question: {question}\n",
    "                Answer:\n",
    "                \"\"\"))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bf4cf-a257-4323-99b7-45d4fd92d73b",
   "metadata": {
    "id": "105bf4cf-a257-4323-99b7-45d4fd92d73b"
   },
   "source": [
    "* [ ] collect metadata from code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba89a7a6-3c3f-4969-bdff-5cc6627d330a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749173904536,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "ba89a7a6-3c3f-4969-bdff-5cc6627d330a"
   },
   "outputs": [],
   "source": [
    "def collect_unique_pairs(documents):\n",
    "    \"\"\"\n",
    "    Collect unique concatenated 'tech_credit: description' strings from document metadata.\n",
    "\n",
    "    Args:\n",
    "        documents (list[dict]): A list of Document objects, each with a 'metadata' field.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of unique 'tech_credit: description' strings.\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "\n",
    "    for doc in documents:\n",
    "        metadata = doc.metadata\n",
    "        credit = metadata.get(\"tech_credit\")\n",
    "        description = metadata.get(\"tech_credit_description\")\n",
    "        if credit and description:\n",
    "            combined = f\"{credit}: {description}\"\n",
    "            seen.add(combined)\n",
    "\n",
    "    return list(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67ceec1c-ca5f-481d-a56c-50a0a00c9341",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749173904555,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "67ceec1c-ca5f-481d-a56c-50a0a00c9341"
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from typing import List\n",
    "\n",
    "def load_repo(url: str, branch: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Loads all Python files from a GitHub repository using the repository URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The full URL of the GitHub repository (e.g., \"https://github.com/org/project\").\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of loaded document objects (the format depends on GithubFileLoader).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the URL is not a valid GitHub repo URL.\n",
    "    \"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    if parsed.netloc != \"github.com\":\n",
    "        raise ValueError(f\"URL is not a github.com repo: {url}\")\n",
    "\n",
    "    # The path is like '/org/project' or '/org/project/'\n",
    "    path_parts = parsed.path.strip('/').split('/')\n",
    "    if len(path_parts) < 2:\n",
    "        raise ValueError(f\"Invalid GitHub repository URL: {url}\")\n",
    "    repo_name = '/'.join(path_parts[:2])  # Only org/project, ignore any deeper paths\n",
    "\n",
    "    loader = GithubFileLoader(\n",
    "        repo=repo_name,\n",
    "        branch=branch,\n",
    "        # access_token=ACCESS_TOKEN,\n",
    "        github_api_url=\"https://api.github.com\",\n",
    "        file_filter=lambda file_path: not file_path.startswith(\"tests/\") and file_path.endswith(\".py\"),\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def split_documents(documents: List[Document]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits Python code documents into code snippets and prepends the code structure as a comment header.\n",
    "\n",
    "    Args:\n",
    "        documents (List[Document]): List of Document objects containing Python code.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: List of new strings, each with a code structure comment followed by the code snippet.\n",
    "    \"\"\"\n",
    "    python_splitter = TiktokenSplitter(Language.Python, max_size=200)\n",
    "\n",
    "    all_splits = []\n",
    "    for doc in documents:\n",
    "        splits = python_splitter.split(doc.page_content.encode(\"utf-8\"))\n",
    "        for snippet in splits:\n",
    "            # delete the header for now, only splitting the literal source code\n",
    "            # header = (\n",
    "            #    \"# ===== code structure =====\\n\" +\n",
    "            #    \"\\n\".join(f\"# {line}\" for line in snippet.subtree.splitlines()) +\n",
    "            #    \"\\n\\n\"\n",
    "            #)\n",
    "            all_splits.append(snippet.text)\n",
    "    return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e7fbf07-ec97-4bea-afe6-ba708826ba10",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749173904561,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "0e7fbf07-ec97-4bea-afe6-ba708826ba10"
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "from typing import Callable\n",
    "from statistics import mean, median # for later usage of different similarity score\n",
    "\n",
    "def default_min_score_fn(results: list[tuple[Document, float]]) -> float:\n",
    "    \"\"\"Default scoring function: returns the minimum score.\"\"\"\n",
    "    return min(score for _, score in results)\n",
    "\n",
    "def top_k_similar_queries(\n",
    "    queries: list[str],\n",
    "    vectorstore,\n",
    "    k: int = 3,\n",
    "    scoring_fn: Callable[[list[tuple[Document, float]]], float] = default_min_score_fn,\n",
    "    top_docs_per_query: int = 4\n",
    ") -> list[tuple[str, list[Document], float]]:\n",
    "    \"\"\"\n",
    "    Executes similarity_search_with_score for each query and returns top-k queries\n",
    "    sorted by a user-defined scoring function.\n",
    "\n",
    "    Args:\n",
    "        queries: List of query strings.\n",
    "        vectorstore: A LangChain-compatible vector store.\n",
    "        k: Number of top results to return.\n",
    "        scoring_fn: Function that maps a list of (Document, score) to a float score.\n",
    "        top_docs_per_query: Number of documents to retrieve for each query.\n",
    "\n",
    "    Returns:\n",
    "        A list of (query, documents, aggregated_score) sorted by aggregated_score descending.\n",
    "    \"\"\"\n",
    "    heap = []\n",
    "\n",
    "    for query in queries:\n",
    "        results = vectorstore.similarity_search_with_score(query, k=top_docs_per_query)\n",
    "        if not results:\n",
    "            continue\n",
    "\n",
    "        agg_score = scoring_fn(results)\n",
    "\n",
    "        # if agg_score < 0.65:\n",
    "        #    continue\n",
    "\n",
    "        docs = [doc for doc, _ in results]\n",
    "\n",
    "        # Use negative score to simulate a max-heap\n",
    "        heapq.heappush(heap, (-agg_score, query, docs))\n",
    "        if len(heap) > k:\n",
    "            heapq.heappop(heap)\n",
    "\n",
    "    # Return sorted results: highest score first\n",
    "    top_k = sorted([(-score, query, docs) for score, query, docs in heap], reverse=True)\n",
    "    return [(query, docs, score) for score, query, docs in top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad89e54e-0483-47d8-bda7-45e4ecec352e",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749173904568,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "ad89e54e-0483-47d8-bda7-45e4ecec352e"
   },
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.vectorstores.base import VectorStore\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context_doc: List[Document]\n",
    "    # a part that contains example codes, user code, tech credit and index order\n",
    "    parts: list[dict]\n",
    "    url: str # user code\n",
    "    branch: str\n",
    "    llm: BaseChatModel\n",
    "    vector_store: VectorStore\n",
    "    answer: str\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    repo_splits = split_documents(load_repo(state[\"url\"], state[\"branch\"]))\n",
    "    retrieved_docs = top_k_similar_queries(repo_splits, state[\"vector_store\"])\n",
    "    parts = [\n",
    "        {\n",
    "            \"ordinal\": i + 1,\n",
    "            \"tech_credit\": \"\\n\".join(collect_unique_pairs(context_code)),\n",
    "            \"user_code\": user_code,\n",
    "            \"context_code\": \"\\n\\n\".join(doc.page_content for doc in context_code)\n",
    "        }\n",
    "        for i, (user_code, context_code, _) in enumerate(retrieved_docs)\n",
    "    ]\n",
    "    return {\"parts\": parts}\n",
    "\n",
    "def retrieve_doc(state: State):\n",
    "    retrieved_doc = document_store.similarity_search(state[\"question\"], k = 3)\n",
    "    return {\"context_doc\": retrieved_doc}\n",
    "\n",
    "def generate(state: State):\n",
    "    doc_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context_doc\"])\n",
    "    user_prompt = user_prompt_template.render(parts=state[\"parts\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"rendered\": user_prompt,\n",
    "                              \"context_doc\": doc_content})\n",
    "    response = state[\"llm\"].invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_node(retrieve_doc)\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(START, \"retrieve_doc\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "r4oIh8fHwkrg",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749173904587,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "r4oIh8fHwkrg"
   },
   "outputs": [],
   "source": [
    "def rag_state_wrapper(user_input: dict, llm, vector_store) -> dict:\n",
    "    \"\"\"\n",
    "    get user input and llm and vector_store to compose the final state\n",
    "    \"\"\"\n",
    "    state = dict(user_input)\n",
    "    state.setdefault(\"context_doc\", [])\n",
    "    state.setdefault(\"parts\", [])\n",
    "    state[\"llm\"] = llm\n",
    "    state[\"vector_store\"] = vector_store\n",
    "    return state\n",
    "\n",
    "# def openai_and_chroma_state(user_input):\n",
    "#     return rag_state_wrapper(user_input,\n",
    "#                              llm=openai_llm, vector_store=vector_store)\n",
    "\n",
    "def anthropic_and_chroma_state(user_input):\n",
    "    return rag_state_wrapper(user_input,\n",
    "                             llm=claude_llm, vector_store=vector_store)\n",
    "\n",
    "# def anthropic_3_5_state(user_input):\n",
    "#     return rag_state_wrapper(user_input,\n",
    "#                              llm=claude_llm_3_5, vector_store=openai_store)\n",
    "\n",
    "# def openai_and_hf_state(user_input):\n",
    "#     return rag_state_wrapper(user_input,\n",
    "#                              llm=openai_llm, vector_store=huggingface_store)\n",
    "\n",
    "# def anthropic_and_hf_state(user_input):\n",
    "#     return rag_state_wrapper(user_input,\n",
    "#                              llm=claude_llm, vector_store=huggingface_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c890ef-9f4b-4f62-929b-64bc5b33b4c4",
   "metadata": {
    "id": "f2c890ef-9f4b-4f62-929b-64bc5b33b4c4"
   },
   "source": [
    "# Ask Question Part\n",
    "Use example code repo\n",
    "\n",
    "1. test for different LLM model and embedding model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb72313-9804-4db0-a3fe-ccd2841f9c6a",
   "metadata": {
    "id": "8bb72313-9804-4db0-a3fe-ccd2841f9c6a"
   },
   "source": [
    "* [ ] Ask questions and test RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "xl7jNX2mgtMg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11216,
     "status": "ok",
     "timestamp": 1749173915806,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "xl7jNX2mgtMg",
    "outputId": "fbbdf5f6-d369-49ab-e6ab-ae7330a2e298"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai_llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response1 \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39minvoke(\u001b[43mopenai_and_chroma_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat tech credits can you identify in this repo?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://github.com/praypratyay/TicTacToe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbranch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---Response from Openai with gemini embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(response1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[34], line 14\u001b[0m, in \u001b[0;36mopenai_and_chroma_state\u001b[1;34m(user_input)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopenai_and_chroma_state\u001b[39m(user_input):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rag_state_wrapper(user_input,\n\u001b[1;32m---> 14\u001b[0m                              llm\u001b[38;5;241m=\u001b[39m\u001b[43mopenai_llm\u001b[49m, vector_store\u001b[38;5;241m=\u001b[39mvector_store)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'openai_llm' is not defined"
     ]
    }
   ],
   "source": [
    "response1 = graph.invoke(openai_and_chroma_state({\n",
    "    \"question\": \"What tech credits can you identify in this repo?\",\n",
    "    \"url\": \"https://github.com/praypratyay/TicTacToe\",\n",
    "    \"branch\": \"main\"}))\n",
    "print(\"---Response from Openai with gemini embeddings\")\n",
    "print(response1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "NfG4dMegz_Ug",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14536,
     "status": "ok",
     "timestamp": 1749173930336,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "NfG4dMegz_Ug",
    "outputId": "22015ea8-bff7-4e9e-ba9a-39f87f697411"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response2 \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43manthropic_and_chroma_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat tech credits can you identify in this repo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://github.com/praypratyay/TicTacToe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbranch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---Response from Anthropic with gemini embeddings---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(response2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\pregel\\__init__.py:2844\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[0m\n\u001b[0;32m   2841\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2842\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2844\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2848\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   2849\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2851\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2853\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2854\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2855\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2856\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2857\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\pregel\\__init__.py:2534\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2532\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2533\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2534\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   2541\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmpty\u001b[49m\n\u001b[0;32m   2543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2544\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\pregel\\runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\pregel\\retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[33], line 41\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     38\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m user_prompt_template\u001b[38;5;241m.\u001b[39mrender(parts\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     39\u001b[0m messages \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrendered\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt,\n\u001b[0;32m     40\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_doc\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc_content})\n\u001b[1;32m---> 41\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39mcontent}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 378\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 782\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_anthropic\\chat_models.py:1503\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1501\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_payload(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1503\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m anthropic\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1505\u001b[0m     _handle_anthropic_bad_request(e)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_anthropic\\chat_models.py:1364\u001b[0m, in \u001b[0;36mChatAnthropic._create\u001b[1;34m(self, payload)\u001b[0m\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\_utils\\_utils.py:283\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\resources\\messages\\messages.py:997\u001b[0m, in \u001b[0;36mMessages.create\u001b[1;34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[0;32m    991\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    994\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    995\u001b[0m     )\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthinking\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\_base_client.py:1314\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1302\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1309\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1311\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1312\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1313\u001b[0m     )\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\_base_client.py:1023\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1020\u001b[0m options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_options(options)\n\u001b[0;32m   1022\u001b[0m remaining_retries \u001b[38;5;241m=\u001b[39m max_retries \u001b[38;5;241m-\u001b[39m retries_taken\n\u001b[1;32m-> 1023\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(request)\n\u001b[0;32m   1026\u001b[0m kwargs: HttpxSendArgs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\_base_client.py:506\u001b[0m, in \u001b[0;36mBaseClient._build_request\u001b[1;34m(self, options, retries_taken)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected JSON data type, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(json_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cannot merge with `extra_body`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 506\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m params \u001b[38;5;241m=\u001b[39m _merge_mappings(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_query, options\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    508\u001b[0m content_type \u001b[38;5;241m=\u001b[39m headers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\_base_client.py:447\u001b[0m, in \u001b[0;36mBaseClient._build_headers\u001b[1;34m(self, options, retries_taken)\u001b[0m\n\u001b[0;32m    437\u001b[0m custom_headers \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    438\u001b[0m headers_dict \u001b[38;5;241m=\u001b[39m _merge_mappings(\n\u001b[0;32m    439\u001b[0m     {\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-stainless-timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(options\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;241m.\u001b[39mread)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m     custom_headers,\n\u001b[0;32m    446\u001b[0m )\n\u001b[1;32m--> 447\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# headers are case-insensitive while dictionaries are not.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m headers \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mHeaders(headers_dict)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\anthropic\\_client.py:196\u001b[0m, in \u001b[0;36mAnthropic._validate_headers\u001b[1;34m(self, headers, custom_headers)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(custom_headers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m), Omit):\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    198\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
      "\u001b[0mDuring task with name 'generate' and id '24495dc5-9a98-2925-f769-02090c0fa5b6'"
     ]
    }
   ],
   "source": [
    "response2 = graph.invoke(anthropic_and_chroma_state({\n",
    "    \"question\": \"What tech credits can you identify in this repo\",\n",
    "    \"url\": \"https://github.com/praypratyay/TicTacToe\",\n",
    "    \"branch\": \"main\"}))\n",
    "print(\"---Response from Anthropic with gemini embeddings---\")\n",
    "print(response2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "u-9oo7t225M4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17186,
     "status": "ok",
     "timestamp": 1749173969249,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "u-9oo7t225M4",
    "outputId": "5b0b9457-cb27-44a7-8245-b86c85552239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Response from Openai with hugging face embeddings---\n",
      "The identified tech credits from the provided code snippets include the Strategy Pattern, which enables interchangeable algorithms through encapsulation, as evidenced by the implementations of different bot strategies in the user's code. Additionally, a Circuit Breaker pattern can be observed that enhances system resilience by detecting service failures, which is illustrated in the second and third code snippets discussing failure management. Overall, both design patterns contribute to modularity and maintainability in software engineering practices.\n"
     ]
    }
   ],
   "source": [
    "response4 = graph.invoke(openai_and_hf_state({\n",
    "    \"question\": \"What tech credits can you identify from this repo?\",\n",
    "    \"url\": \"https://github.com/praypratyay/TicTacToe\",\n",
    "    \"branch\": \"main\"}))\n",
    "print(\"---Response from Openai with hugging face embeddings---\")\n",
    "print(response4[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "SJ5zskfR0CB4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21697,
     "status": "ok",
     "timestamp": 1749173952073,
     "user": {
      "displayName": "Pusen Yi",
      "userId": "01379187866927987736"
     },
     "user_tz": -600
    },
    "id": "SJ5zskfR0CB4",
    "outputId": "4399941c-7d0d-4b27-be67-80b59d5c1653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Response from Anthropic with hugging face embeddings---\n",
      "Based on the provided code snippets, I can identify the following technical credits:\n",
      "\n",
      "**Strategy Pattern Implementation**: The `BotPlayingStrategy` code demonstrates a clear implementation of the Strategy pattern with an abstract base class and multiple concrete strategies (EASY, MEDIUM, HARD). This creates technical credit by allowing different bot playing algorithms to be easily swapped and extended without modifying existing code. The pattern enables future modifications to bot behavior through simple strategy replacement.\n",
      "\n",
      "**Builder Pattern**: The `GameBuilder` class implements the Builder pattern with method chaining, providing a flexible way to construct game objects with different configurations. This creates technical credit by making game creation more maintainable and allowing easy addition of new configuration parameters. The fluent interface design facilitates future extensions to game setup requirements.\n",
      "\n",
      "**Encapsulation with Property Management**: The `Board` class uses private attributes with property decorators to control access to internal state, creating technical credit through proper encapsulation. This design enables future validation logic and access control without breaking existing client code. The abstraction protects against direct manipulation while maintaining flexibility for future enhancements.\n"
     ]
    }
   ],
   "source": [
    "response3 = graph.invoke(anthropic_and_hf_state({\n",
    "    \"question\": \"What tech credits can you identify from this repo?\",\n",
    "    \"url\": \"https://github.com/praypratyay/TicTacToe\",\n",
    "    \"branch\": \"main\"}))\n",
    "print(\"---Response from Anthropic with hugging face embeddings---\")\n",
    "print(response3[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55647081-6115-437c-9efe-09e364b8e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Response from Anthropic with gemini embeddings---\n",
      "Based on the code snippets provided, I cannot identify a clear adapter pattern implementation in this repository. The code shows examples of the Strategy pattern with `BotPlayingStrategy` and its concrete implementations (`EASYBotPlayingStrategy`, `MEDIUMBotPlayingStrategy`, `HARDBotPlayingStrategy`), and a Factory pattern with `BotPlayingStrategyFactory`. \n",
      "\n",
      "The adapter pattern would typically involve wrapping an existing class with an incompatible interface to make it work with another class, but none of the provided code demonstrates this structural pattern. The examples focus on behavioral patterns like Strategy and Template Method rather than adapter-style interface compatibility solutions.\n"
     ]
    }
   ],
   "source": [
    "response_one_tc = graph.invoke(anthropic_and_chroma_state({\n",
    "    \"question\": \"Can you identify an adapter pattern as tech credit in this repo?\",\n",
    "    \"url\": \"https://github.com/praypratyay/TicTacToe\",\n",
    "    \"branch\": \"main\"}))\n",
    "print(\"---Response from Anthropic with gemini embeddings---\")\n",
    "print(response_one_tc[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe566a7-f5bf-4417-a90a-84ad342cf435",
   "metadata": {
    "id": "1fe566a7-f5bf-4417-a90a-84ad342cf435",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Roadmap:\n",
    "\n",
    "1. Use a text embedding model.\n",
    "   + [X] gemini text-embedding-004\n",
    "   + [X] huggingface sentence-transformers/all-mpnet-base-v2\n",
    "   + [ ] OpenAI text embedding large \n",
    "2. Code splitter may not work properly.\n",
    "   + [X] change to code-splitter that works better.\n",
    "3. [X] Switch in memory vector storage to a vector database\n",
    "   + [X] code vector database with additional metadata for tech credit\n",
    "   + [X] document vector database with academic context about tech credit\n",
    "4. [ ] Load more standard example codes for tech credit (~20 more examples)\n",
    "5. [ ] Load more documents (academic contexts) for technical credit (3~5 related academic paper)\n",
    "6. [X] Allow user to ask about a repository, instead of small snippets of codes\n",
    "   * [X] load, chunk, split, embed and vectorize a repo\n",
    "   * [X] similarity search and filter user code by similarity score compared with example code\n",
    "   * [ ] batch process to LLM\n",
    "   * [ ] organize response and answers\n",
    "7. [ ] validate the results\n",
    "   * [ ] Test our trained data in TC-Examples\n",
    "   * [ ] use different embedding and LLM to test five example repos\n",
    "   * Gemini,\n",
    "   * claude-3.5-haiku, claude-sonnet-4\n",
    "   * OpenAI gpt-4o-mini"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tcai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ec0f76-970a-47cd-aa1e-0a2e1a6ad92f",
   "metadata": {},
   "source": [
    "# Preview from LangChain\n",
    "\n",
    "## Step by step code\n",
    "\n",
    "1. get LangSmith API Key from environment\n",
    "2. set up anthropic key for chat model\n",
    "3. set up embedding model for embeddings\n",
    "4. select vector database\n",
    "5. set up document loader and split up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8825c3-e6e4-4541-aa62-fc862ba42bc6",
   "metadata": {},
   "source": [
    "## Tutorials\n",
    "\n",
    "### LangChain RAG tutorial document\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "- https://python.langchain.com/docs/tutorials/rag\n",
    "\n",
    "#### Part 2\n",
    "\n",
    "Extends the implementation to accommodate conversation-style interactions and multi-step retrieval processes.\n",
    "\n",
    "- https://python.langchain.com/docs/tutorials/qa_chat_history/\n",
    "\n",
    "LangChain document loader for GitHub Repo\n",
    "\n",
    "- https://python.langchain.com/docs/integrations/document_loaders/github/\n",
    "\n",
    "LangChain document loader for Git Repository\n",
    "\n",
    "- https://python.langchain.com/docs/integrations/document_loaders/git/\n",
    "\n",
    "LangChain document loader for Source Code (e.g. Python)\n",
    "\n",
    "- https://python.langchain.com/docs/integrations/document_loaders/source_code/\n",
    "\n",
    "LangSmith evaluation for a chatbot\n",
    "\n",
    "- https://docs.smith.langchain.com/evaluation/tutorials/evaluation\n",
    "\n",
    "LangSmith evaluation for a rag\n",
    "\n",
    "- https://docs.smith.langchain.com/evaluation/tutorials/rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab7270",
   "metadata": {},
   "source": [
    "### 1000 Imports\n",
    "\n",
    "* [x] set up LangSmith key\n",
    "* [x] set up Claude key (Anthropic)\n",
    "* [x] set up Gemini key (Google)\n",
    "* [x] set up Github personal access token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fd66b",
   "metadata": {},
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a355670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from typing import Callable, List\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import GithubFileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23ba444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the parent directory of the notebook\n",
    "parent_dir = os.path.dirname(os.path.abspath(\"\"))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Now do the import\n",
    "from helper.secrets_loader import SecretsLoader\n",
    "\n",
    "envfile = os.path.join(parent_dir, \".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b899eece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LANGSMITH_API_KEY from token file: /Users/ejacquin/Desktop/Northeastern/SchoolWork/Summer_II_2025/CS4973/techcredit/.env\n",
      "Loaded CLAUDE_API_KEY from token file: /Users/ejacquin/Desktop/Northeastern/SchoolWork/Summer_II_2025/CS4973/techcredit/.env\n",
      "Loaded GOOGLE_API_KEY from token file: /Users/ejacquin/Desktop/Northeastern/SchoolWork/Summer_II_2025/CS4973/techcredit/.env\n",
      "Loaded GITHUB_PA_TOKEN from token file: /Users/ejacquin/Desktop/Northeastern/SchoolWork/Summer_II_2025/CS4973/techcredit/.env\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = SecretsLoader.get_token(\"LANGSMITH_API_KEY\", envfile)\n",
    "os.environ[\"CLAUDE_API_KEY\"] = SecretsLoader.get_token(\"CLAUDE_API_KEY\", envfile)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = SecretsLoader.get_token(\"GOOGLE_API_KEY\", envfile)\n",
    "os.environ[\"GITHUB_PA_TOKEN\"] = SecretsLoader.get_token(\"GITHUB_PA_TOKEN\", envfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef6207e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter constants (like C macros) - each returns a lambda function\n",
    "class FileFilters:\n",
    "    \"\"\"Collection of file filter constants that can be combined with logical operations\"\"\"\n",
    "    \n",
    "    # Extension filters\n",
    "    PYTHON_FILES = lambda file_path: file_path.endswith(\".py\")\n",
    "    JAVASCRIPT_FILES = lambda file_path: file_path.endswith((\".js\", \".jsx\"))\n",
    "    TYPESCRIPT_FILES = lambda file_path: file_path.endswith((\".ts\", \".tsx\"))\n",
    "    JSON_FILES = lambda file_path: file_path.endswith(\".json\")\n",
    "    MARKDOWN_FILES = lambda file_path: file_path.endswith((\".md\", \".markdown\"))\n",
    "    YAML_FILES = lambda file_path: file_path.endswith((\".yml\", \".yaml\"))\n",
    "    \n",
    "    # Directory exclusion filters\n",
    "    NOT_TESTS = lambda file_path: not file_path.startswith(\"tests/\") and \\\n",
    "        not file_path.startswith(\"test/\")\n",
    "    NOT_NODE_MODULES = lambda file_path: \"node_modules\" not in file_path\n",
    "    NOT_DIST = lambda file_path: not file_path.startswith(\"dist/\") and \\\n",
    "        not file_path.startswith(\"build/\")\n",
    "    NOT_CACHE = lambda file_path: \\\n",
    "        not any(cache_dir in file_path for cache_dir in [\"__pycache__\", \".cache\", \"cache/\"])\n",
    "    NOT_HIDDEN = lambda file_path: \\\n",
    "        not any(part.startswith(\".\") for part in file_path.split(\"/\"))\n",
    "    NOT_VENV = lambda file_path: \\\n",
    "        not any(venv_dir in file_path for venv_dir in [\"venv/\", \"env/\", \".env/\", \"virtualenv/\"])\n",
    "    \n",
    "    # Directory inclusion filters\n",
    "    @staticmethod\n",
    "    def FOLDER_ONLY(folder_name: str):\n",
    "        \"\"\"\n",
    "        Creates a filter that only includes files from a specific folder.\n",
    "        \n",
    "        Args:\n",
    "            folder_name (str): The folder name/path to include (e.g., \"src\", \"lib\", \"utils/helpers\")\n",
    "            \n",
    "        Returns:\n",
    "            A lambda function that filters for files in the specified folder\n",
    "            \n",
    "        Examples:\n",
    "            FileFilters.FOLDER_ONLY(\"src\")  # Only files in src/ folder\n",
    "            FileFilters.FOLDER_ONLY(\"lib/utils\")  # Only files in lib/utils/ folder\n",
    "        \"\"\"\n",
    "        # Normalize folder name to ensure it ends with /\n",
    "        normalized_folder = folder_name.rstrip('/') + '/'\n",
    "        return lambda file_path: file_path.startswith(normalized_folder)\n",
    "    \n",
    "    @staticmethod\n",
    "    def FOLDERS_ONLY(*folder_names):\n",
    "        \"\"\"\n",
    "        Creates a filter that includes files from multiple specific folders.\n",
    "        \n",
    "        Args:\n",
    "            *folder_names: Variable number of folder names to include\n",
    "            \n",
    "        Returns:\n",
    "            A lambda function that filters for files in any of the specified folders\n",
    "            \n",
    "        Examples:\n",
    "            FileFilters.FOLDERS_ONLY(\"src\", \"lib\")  # Files in src/ OR lib/\n",
    "            FileFilters.FOLDERS_ONLY(\"components\", \"utils\", \"services\")  # Multiple folders\n",
    "        \"\"\"\n",
    "        normalized_folders = [folder.rstrip('/') + '/' for folder in folder_names]\n",
    "        return lambda file_path: any(file_path.startswith(folder) for folder in normalized_folders)\n",
    "    \n",
    "    # Common combinations\n",
    "    PYTHON_SOURCE_ONLY = [PYTHON_FILES, NOT_TESTS, NOT_CACHE, NOT_HIDDEN]\n",
    "    WEB_SOURCE_FILES = [lambda f: any(f.endswith(ext) for ext in \\\n",
    "                                      [\".js\", \".jsx\", \".ts\", \".tsx\", \".css\", \".html\"]), \\\n",
    "                                        NOT_NODE_MODULES, NOT_DIST]\n",
    "\n",
    "\n",
    "def combine_filters(*filters) -> Callable[[str], bool]:\n",
    "    \"\"\"\n",
    "    Combine multiple filter functions with logical AND operation.\n",
    "    \n",
    "    Args:\n",
    "        *filters: Variable number of filter functions or lists of filter functions\n",
    "        \n",
    "    Returns:\n",
    "        A single filter function that applies all filters with AND logic\n",
    "    \"\"\"\n",
    "    # Flatten any nested lists\n",
    "    flat_filters = []\n",
    "    for f in filters:\n",
    "        if isinstance(f, list):\n",
    "            flat_filters.extend(f)\n",
    "        else:\n",
    "            flat_filters.append(f)\n",
    "    \n",
    "    def combined_filter(file_path: str) -> bool:\n",
    "        return all(filter_func(file_path) for filter_func in flat_filters)\n",
    "    \n",
    "    return combined_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cec9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_repo_contents(documents: List[Document], repo_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Print all document paths/names from a loaded repository for debugging.\n",
    "    \n",
    "    Args:\n",
    "        documents (List[Document]): List of loaded documents\n",
    "        repo_name (str): Name of the repository for context\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Repository Contents: {repo_name} ===\")\n",
    "    print(f\"Total files loaded: {len(documents)}\")\n",
    "    print(\"Files:\")\n",
    "    \n",
    "    for i, doc in enumerate(documents, 1):\n",
    "        # Extract path from metadata or use a fallback\n",
    "        file_path = doc.metadata.get('path', f'document_{i}')\n",
    "        file_size = len(doc.page_content)\n",
    "        print(f\"  {i:2d}. {file_path} ({file_size:,} chars)\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "\n",
    "def load_repo(url: str, branch: str, *filters, debug: bool = True) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Loads files from a GitHub repository using the repository URL with customizable filters.\n",
    "\n",
    "    Args:\n",
    "        url (str): The full URL of the GitHub repository (e.g., \"https://github.com/org/project\").\n",
    "        branch (str): The branch name to load from.\n",
    "        *filters: Variable number of filter functions or lists of filter functions to apply.\n",
    "                 If no filters provided, defaults to Python files only.\n",
    "        debug (bool): Whether to print debug information about loaded files. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of loaded document objects.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the URL is not a valid GitHub repo URL.\n",
    "        \n",
    "    Examples:\n",
    "        # Load only Python files (default behavior)\n",
    "        load_repo(\"https://github.com/org/repo\", \"main\")\n",
    "        \n",
    "        # Load Python files excluding tests\n",
    "        load_repo(\"https://github.com/org/repo\", \"main\", \n",
    "                 FileFilters.PYTHON_FILES, FileFilters.NOT_TESTS)\n",
    "        \n",
    "        # Load multiple file types excluding common directories\n",
    "        load_repo(\"https://github.com/org/repo\", \"main\",\n",
    "                 FileFilters.PYTHON_FILES, FileFilters.JAVASCRIPT_FILES,\n",
    "                 FileFilters.NOT_TESTS, FileFilters.NOT_NODE_MODULES)\n",
    "        \n",
    "        # Use predefined combinations\n",
    "        load_repo(\"https://github.com/org/repo\", \"main\", *FileFilters.PYTHON_SOURCE_ONLY)\n",
    "        \n",
    "        # Disable debug output\n",
    "        load_repo(\"https://github.com/org/repo\", \"main\", debug=False)\n",
    "    \"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    if parsed.netloc != \"github.com\":\n",
    "        raise ValueError(f\"URL is not a github.com repo: {url}\")\n",
    "\n",
    "    # The path is like '/org/project' or '/org/project/'\n",
    "    path_parts = parsed.path.strip('/').split('/')\n",
    "    if len(path_parts) < 2:\n",
    "        raise ValueError(f\"Invalid GitHub repository URL: {url}\")\n",
    "    repo_name = '/'.join(path_parts[:2])  # Only org/project, ignore any deeper paths\n",
    "\n",
    "    # Default to Python files if no filters provided\n",
    "    if not filters:\n",
    "        filters = [FileFilters.PYTHON_FILES]\n",
    "    \n",
    "    # Combine all filters with logical AND\n",
    "    combined_filter = combine_filters(*filters)\n",
    "\n",
    "    loader = GithubFileLoader(\n",
    "        repo=repo_name,\n",
    "        branch=branch,\n",
    "        access_token=os.environ[\"GITHUB_PA_TOKEN\"],\n",
    "        github_api_url=\"https://api.github.com\",\n",
    "        file_filter=combined_filter,\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Debug output\n",
    "    if debug:\n",
    "        print_repo_contents(documents, repo_name)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ad272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from code_splitter import Language, TiktokenSplitter\n",
    "\n",
    "def split_documents(documents: List[Document], metadata_map={}) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Splits Python code documents into code snippets and prepends the code structure as a comment\n",
    "    header.\n",
    "\n",
    "    Args:\n",
    "        documents (List[Document]): List of Document objects containing Python code.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: List of new strings, each with a code structure comment followed by the\n",
    "        code snippet.\n",
    "    \"\"\"\n",
    "    python_splitter = TiktokenSplitter(Language.Python, max_size=200)\n",
    "\n",
    "    all_splits = []\n",
    "    for doc in documents:\n",
    "        splits = python_splitter.split(doc.page_content.encode(\"utf-8\"))\n",
    "        for snippet in splits:\n",
    "            # delete the header for now, only splitting the literal source code\n",
    "            # header = (\n",
    "            #    \"# ===== code structure =====\\n\" +\n",
    "            #    \"\\n\".join(f\"# {line}\" for line in snippet.subtree.splitlines()) +\n",
    "            #    \"\\n\\n\"\n",
    "            #)\n",
    "            all_splits.append(Document(\n",
    "                page_content=(\n",
    "                    snippet.text\n",
    "                ),\n",
    "                metadata=metadata_map.get(doc.metadata.get('path'), {})\n",
    "            ))\n",
    "    return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac315b7b-3b72-4f20-a641-9b2b498a7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "llm = init_chat_model(\n",
    "    \"claude-3-5-haiku-latest\", \n",
    "    model_provider=\"anthropic\",\n",
    "    api_key=os.environ[\"CLAUDE_API_KEY\"]\n",
    ")\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5954c2e3-3c86-41f1-9ce2-d76e5fb88ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"python_tech_credit\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "document_store = Chroma(\n",
    "    collection_name=\"document_tech_credit\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032cc2a-ae18-40bf-86aa-08270b25fc32",
   "metadata": {},
   "source": [
    "* [x] set up Claude (Anthropic) llm\n",
    "* [x] set up Google Gemini as embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7a684-56c6-40e1-8a64-b86089a6e12c",
   "metadata": {},
   "source": [
    "# Choosing database\n",
    "\n",
    "Load, chunk, split, embed and vectorize code data and document data into database\n",
    "\n",
    "## Candidates\n",
    "\n",
    "1. cassandra\n",
    "2. open search https://opensearch.org/platform/os-search/vector-database/\n",
    "3. Pinecone\n",
    "4. MongoDB\n",
    "5. PostgreSQL\n",
    "6. [x] Chroma, locally hosted with sqlite --> **using this one**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf0591-3020-489b-9563-00a12e3a20bb",
   "metadata": {},
   "source": [
    "* [ ] Import and load a GitHub Repo as a document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4df20-f761-4288-b10a-574e3a2a21f4",
   "metadata": {},
   "source": [
    "* [ ] test documents content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ee1cb4-7571-4e12-a190-58e53b4d6be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repository Contents: ameliarogerscodes/TC-Examples ===\n",
      "Total files loaded: 14\n",
      "Files:\n",
      "   1. Adapter/adapterex.py (1,408 chars)\n",
      "   2. ChainOfResponsibility/chain_of_res_ex.py (2,727 chars)\n",
      "   3. CircuitBreaker/CircuitBreaker.py (4,885 chars)\n",
      "   4. Iterator/iter_ex.py (1,816 chars)\n",
      "   5. MVC/controller.py (416 chars)\n",
      "   6. MVC/main.py (106 chars)\n",
      "   7. MVC/model.py (185 chars)\n",
      "   8. MVC/view.py (252 chars)\n",
      "   9. PlatformAbstractionLayers/BasicAbstractionPatternEx.py (451 chars)\n",
      "  10. Proxy/proxyex.py (2,414 chars)\n",
      "  11. Strategy/strategyex.py (2,606 chars)\n",
      "  12. Template/templateex.py (3,118 chars)\n",
      "  13. Visitor/visitorex.py (3,852 chars)\n",
      "  14. scripts/generate_repo_metadata.py (1,516 chars)\n",
      "==================================================\n",
      "\n",
      "Summary: Successfully loaded 14 Python files\n",
      "Sample metadata from document 8: {'path': 'MVC/view.py', 'sha': '906c1ec1fe1d4d79a7e8b9fbdf80ab20e17236a0', 'source': 'https://api.github.com/ameliarogerscodes/TC-Examples/blob/main/MVC/view.py'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# Load and chunk contents of the github repo using the new filter system\n",
    "# Old way (commented out):\n",
    "# loader = GithubFileLoader(\n",
    "#     repo=\"ameliarogerscodes/TC-Examples\",  # the repo name\n",
    "#     access_token=os.environ[\"GITHUB_PA_TOKEN\"],\n",
    "#     branch=\"main\",  # the branch name\n",
    "#     github_api_url=\"https://api.github.com\",\n",
    "#     file_filter=lambda file_path: file_path.endswith(\n",
    "#         \".py\"\n",
    "#     ),  # load all python files.\n",
    "# )\n",
    "\n",
    "# New way using the filter system with debug output:\n",
    "documents = load_repo(\n",
    "    \"https://github.com/ameliarogerscodes/TC-Examples\", \n",
    "    \"main\", \n",
    "    FileFilters.PYTHON_FILES,  # This is equivalent to the old lambda\n",
    ")\n",
    "\n",
    "# Additional debugging\n",
    "print(f\"\\nSummary: Successfully loaded {len(documents)} Python files\")\n",
    "if documents and len(documents) > 7:\n",
    "    print(\"Sample metadata from document 8:\", documents[7].metadata)\n",
    "elif documents:\n",
    "    print(\"Sample metadata from first document:\", documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d2c29e-4580-4232-b678-8db2d4028644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adapter/adapterex.py': {'type': 'source', 'tech_credit': 'Adapter Pattern', 'tech_credit_description': 'Convert the interface of an existing class into another interface clients expect. Adapter allows classes with incompatible interfaces to work together, promoting system flexibility and reducing the cost of integration with third-party or legacy components.'}, 'ADRs/api-with-abstraction-usecase': {'type': 'source', 'tech_credit': 'Architecture Design Records', 'tech_credit_description': 'Document architectural decisions in a lightweight, structured format to improve traceability, promote team alignment, and support future system evolution. ADRs capture the rationale, context, and alternatives behind design choices, enabling resilient and maintainable architecture.'}, 'ADRs/configuration-management-usecase': {'type': 'source', 'tech_credit': 'Architecture Design Records', 'tech_credit_description': 'Document architectural decisions in a lightweight, structured format to improve traceability, promote team alignment, and support future system evolution. ADRs capture the rationale, context, and alternatives behind design choices, enabling resilient and maintainable architecture.'}, 'ADRs/sql-in-dev-usecase': {'type': 'source', 'tech_credit': 'Architecture Design Records', 'tech_credit_description': 'Document architectural decisions in a lightweight, structured format to improve traceability, promote team alignment, and support future system evolution. ADRs capture the rationale, context, and alternatives behind design choices, enabling resilient and maintainable architecture.'}, 'ArchitectureDesignRecords/Architecture_Design_Records_Ex': {'type': 'source', 'tech_credit': 'Architecture Design Records', 'tech_credit_description': 'Document architectural decisions in a lightweight, structured format to improve traceability, promote team alignment, and support future system evolution. ADRs capture the rationale, context, and alternatives behind design choices, enabling resilient and maintainable architecture.'}, 'ChainOfResponsibility/chain_of_res_ex.py': {'type': 'source', 'tech_credit': 'Chain of responsibility', 'tech_credit_description': 'Avoid coupling the sender of a request to its receiver by giving more than one object a chance to handle the request. Chain the receiving objects and pass the request along the chain until an object handles it.'}, 'CircuitBreaker/CircuitBreaker.py': {'type': 'source', 'tech_credit': 'Circuit Breaker', 'tech_credit_description': 'Enhance system resilience by dynamically detecting service failures and preventing cascading issues, especially in distributed systems.'}, 'CircuitBreaker/PyCircuitBreaker.py': {'type': 'source', 'tech_credit': 'Circuit Breaker', 'tech_credit_description': 'Enhance system resilience by dynamically detecting service failures and preventing cascading issues, especially in distributed systems.'}, 'Iterator/iter_ex.py': {'type': 'source', 'tech_credit': 'Iterator', 'tech_credit_description': 'Provide a way to access the elements of an aggregate object sequentially without exposing its underlying representation.'}, 'MVC/controller.py': {'type': 'source', 'tech_credit': 'Model View Controller', 'tech_credit_description': 'Separate application concerns into three interconnected components: Model for business logic and data, View for user interface, and Controller for input handling. MVC promotes modularity, enabling independent development, testing, and reuse of each component.'}, 'MVC/main.py': {'type': 'source', 'tech_credit': 'Model View Controller', 'tech_credit_description': 'Separate application concerns into three interconnected components: Model for business logic and data, View for user interface, and Controller for input handling. MVC promotes modularity, enabling independent development, testing, and reuse of each component.'}, 'MVC/model.py': {'type': 'source', 'tech_credit': 'Model View Controller', 'tech_credit_description': 'Separate application concerns into three interconnected components: Model for business logic and data, View for user interface, and Controller for input handling. MVC promotes modularity, enabling independent development, testing, and reuse of each component.'}, 'MVC/view.py': {'type': 'source', 'tech_credit': 'Model View Controller', 'tech_credit_description': 'Separate application concerns into three interconnected components: Model for business logic and data, View for user interface, and Controller for input handling. MVC promotes modularity, enabling independent development, testing, and reuse of each component.'}, 'PlatformAbstractionLayers/BasicAbstractionPatternEx.py': {'type': 'source', 'tech_credit': 'Platform Abstraction Layers', 'tech_credit_description': 'Introduce intermediary layers that decouple application logic from third-party platforms, libraries, or APIs. This shields the core system from external changes, simplifies technology replacement, and reduces the cost and risk of platform evolution.'}, 'Proxy/proxyex.py': {'type': 'source', 'tech_credit': 'Proxy', 'tech_credit_description': 'Provide a surrogate or placeholder for another object to control access to it.'}, 'Strategy/strategyex.py': {'type': 'source', 'tech_credit': 'Strategy Pattern', 'tech_credit_description': 'Define a family of algorithms, encapsulate each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it.'}, 'Template/templateex.py': {'type': 'source', 'tech_credit': 'Template method', 'tech_credit_description': \"Define the skeleton of an algorithm in an operation, deferring some steps to subclasses. Template method lets subclasses redefine certain steps of an algorithm without changing the algorithm's structure.\"}, 'Visitor/visitorex.py': {'type': 'source', 'tech_credit': 'Visitor Pattern', 'tech_credit_description': 'Represent an operation to be performed on instances of a set of classes. Visitor lets a new operation be defined without changing the classes of the elements on which it operates.'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Step 1: Load the JSON metadata from a file (adjust path accordingly)\n",
    "with open('../repo_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    metadata_map = json.load(f)\n",
    "\n",
    "print(metadata_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a26421b-1478-4354-a169-62389fdd8d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 34 NEW Page Content:  class ConcreteComponentA(Component):\n",
      "    \"\"\"\n",
      "    Each Concrete Component must implement the `accept` method in such a way\n",
      "    that it calls the visitor's method corresponding to the component's class.\n",
      "    \"\"\"\n",
      "\n",
      "    def accept(self, visitor: Visitor) -> None:\n",
      "        \"\"\"\n",
      "        Note that we're calling `visitConcreteComponentA`, which matches the\n",
      "        current class name. This way we let the visitor know the class of the\n",
      "        component it works with.\n",
      "        \"\"\"\n",
      "\n",
      "        visitor.visit_concrete_component_a(self)\n",
      "\n",
      "    def exclusive_method_of_concrete_component_a(self) -> str:\n",
      "        \"\"\"\n",
      "        Concrete Components may have special methods that don't exist in their\n",
      "        base class or interface. The Visitor is still able to use these methods\n",
      "        since it's aware of the component's concrete class.\n",
      "        \"\"\"\n",
      "\n",
      "        return \"A\"\n",
      "==================================================\n",
      "Split 34 NEW Metadata:  {'type': 'source', 'tech_credit': 'Visitor Pattern', 'tech_credit_description': 'Represent an operation to be performed on instances of a set of classes. Visitor lets a new operation be defined without changing the classes of the elements on which it operates.'}\n"
     ]
    }
   ],
   "source": [
    "from code_splitter import Language, TiktokenSplitter\n",
    "# use code-splitter \n",
    "# https://pypi.org/project/code-splitter/\n",
    "python_splitter = TiktokenSplitter(Language.Python, max_size=200)\n",
    "\n",
    "all_splits = split_documents(documents, metadata_map=metadata_map)\n",
    "\n",
    "print(\"Split 34 NEW Page Content: \", all_splits[34].page_content)\n",
    "print(\"=\" * 50)\n",
    "print(\"Split 34 NEW Metadata: \", all_splits[34].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb1b2a-4c2a-49f7-beae-e5200e0eee85",
   "metadata": {},
   "source": [
    "* [ ] map metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abeffb-07c5-4036-95ef-320590c19b61",
   "metadata": {},
   "source": [
    "* [X] use code splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280decb5-9f05-4303-9964-b10df988ab5c",
   "metadata": {},
   "source": [
    "* [ ] print page_content and metadata for a split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ffe88-73d0-4bc0-9b33-299d1139db49",
   "metadata": {},
   "source": [
    "* [ ] load, split and embed documents into vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfc96a-85ce-4a0b-9da0-4b7d00c46e23",
   "metadata": {},
   "source": [
    "* [x] index chunks for code vector db, DO NOT LOAD TWICE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57fa4981-55e9-40d1-9df3-b1891d549073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "code_embed_index = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f39c77-6a6d-4979-a565-3bdc65236170",
   "metadata": {},
   "source": [
    "* [ ] load, chunk, split and embed documents about technical credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b926570a-74c5-4b24-8b75-a830ab290d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 13704\n",
      "==================================================\n",
      "Split articles into 15 chunks\n",
      "==================================================\n",
      "Article Chunks:\n",
      "\n",
      "\n",
      "Technical debt (TD) is an established concept in software engineering encompassing an unavoidable side effect of software development.3 It arises due to tight schedules, which often prioritizes short-term delivery goals over long-term product quality concerns.3 Even when long-term planning is feasible, the continuous evolution of requirements and technology platforms necessitates design decisions and code revision. Inevitably, even the best software designs will deteriorate over time, leading to TD.5Addressing TD is an essential task that entails continuous efforts to refactor code bases, update integrated third-party components, and resolve low-priority bugs.6 Similar to managing personal finances or parenting teenagers, a living software system requires constant attention to TD. Simply, TD is an unavoidable aspect of the software development process. TD has been a subject of extensive research and analysis within the software engineering community. In many ways, TD is the gift that\n",
      "==================================================\n",
      "research and analysis within the software engineering community. In many ways, TD is the gift that keeps on giving for the research community, delivering an endless source of problems to study from the vast global ecosystem of the software industry. It is simply an intrinsic problem in software engineering that will never go away. Not while humans write code.Surprisingly, the software engineering literature has yet to explore the opposite concept of TD, namely Technical Credit (TC). While TD creates friction that decreases a project’s velocity over time, TC reduces development friction by greasing the wheels of evolution for a software system. Recognizing this gap in research, the primary objective of this Opinion column is to introduce the concept of TC in the context of software engineering. In particular, we propose a definition of TC and present an abstract model to provide a comprehensive understanding of the concept. Furthermore, we provide real-world examples of TC and outline\n",
      "==================================================\n",
      "understanding of the concept. Furthermore, we provide real-world examples of TC and outline a set of research questions that must be addressed to effectively implement TC management in practice.What Is Technical Credit?Essentially, TC characterizes system features that can yield long-term benefits as the system evolves. By highlighting the benefits of strategic investment, TC contrasts with the conventional TD-driven focus on the drawbacks of sub-optimal choices. Rather, TC advocates for a paradigm shift toward recognizing the positive potential of forward-thinking decisions. We believe that framing TC as a counterbalance to the dominant technical debt-centric view can unlock a more nuanced, rounded understanding of a system’s attributes, qualities, and its intrinsic value and investment.While largely absent from the software engineering literature, TC was described by Berenbach in systems engineering.2 Berenbach defines TC as extra effort put into designing, and building systems in\n",
      "==================================================\n",
      "engineering.2 Berenbach defines TC as extra effort put into designing, and building systems in anticipation of future benefits from emergent properties—systems engineering terminology for unknown future requirements. Essentially, all valuable systems evolve to add new functionalities. While the exact path of this evolution is unpredictable, some paths are likelier than others.For example, an online payment system is unlikely to transform into an electronic health record system. Yet, it might need to adapt to new payment methods, support emerging payment devices and new countries, and so on. Hence, when developing applications within a particular domain, having knowledge about that domain, product plans and roadmaps can provide valuable insights into the likely directions that the product may take. These insights make it possible for developers to strategically engineer capabilities into a product to reduce the cost and effort required for likely enhancements. These forward-thinking\n",
      "==================================================\n",
      "a product to reduce the cost and effort required for likely enhancements. These forward-thinking capabilities collectively embody a system’s technical credit.Technical credit is not a cost-free endeavor. It necessitates an initial investment to establish the necessary capabilities to enhance future modifications. Figure 1 illustrates that such an investment can lead to returns over time, once the break-even point is achieved. The key is to minimize the investment in technical credit while maximizing effort and cost saving that result from the technical credit investment downstream. In light of this, we define technical credit as follows: “Technical credit is the benefits that result from making strategic design decisions that require a higher initial investment, but offer highly advantageous long-term effects for the evolution of a system.”\n",
      "==================================================\n",
      "Figure 1.  Technical credit. To exemplify this concept, imagine a system that relies on an external provider for email delivery. In this setup, there are two primary ways to structure the system: each service interfaces directly with the email vendor’s API or the system uses an intermediary edge service that wraps the email vendor’s API, with all services sending email through this edge service.In this scenario, using an edge service represents TC. With multiple email vendors in the market, their prices and features might change, necessitating a vendor switch. In such a case, updating the edge service to accommodate a new vendor is faster and more cost-efficient than altering each service’s direct API calls to the email vendor. When you switch vendor, you cash in your technical credit. However, if you never switch email vendors, you never exploit TC, representing over-engineering or a YAGNI (You Ain’t Gonna Need It) feature—something agilistas caution against.This highlights why\n",
      "==================================================\n",
      "a YAGNI (You Ain’t Gonna Need It) feature—something agilistas caution against.This highlights why having deep knowledge of the domain, business, and product is essential as not every investment will yield returns, underscoring the importance of strategic planning.During the Dagstuhl Seminar 16162, Avgeriou et al. developed a conceptual model for TD.1 Building on this, Figure 2 introduces a conceptual model for TC. TC comprises of a set of items, each with associated causes and consequences. The cause of TC is one or more design decisions. The consequences of TC impact the architecture and its qualities, the system costs, and development process. For example, a particular design decision may enhance the modifiability of a system, reducing the cost of future changes. Similarly. TC can affect the development process by reducing delays when prescriptive and informative instruments are utilized. A TC item relates to one or more specific, tangible artifacts. It should be noted this\n",
      "==================================================\n",
      "utilized. A TC item relates to one or more specific, tangible artifacts. It should be noted this conceptual model does not account for approaches to TC measurement and analysis, the activities necessary to manage TC, or the various states that credit may go through.\n",
      "==================================================\n",
      "Figure 2.  Conceptual model of technical credit.1 Technical Credit in PracticeDecisions leading to TC are inherently connected to a system’s business domain and product roadmap. However, not all design decisions yield true TC: those not enabling cost-effective modifications in line with business objectives might be deemed over-engineering. We create TC by crafting design decisions that ease future modifications anticipated by the product’s roadmap. Thus, a design decision yields technical credit upon its utilization.Drawing on extensive experience with product, architecture, and code reviews, we have identified examples of TC across different application domains.Platform abstraction layer.  This strategy creates abstraction layers around third-party products and libraries, protecting application code from external API changes. When these products need replacing, adjustments are made only to the abstraction layer, not the application code. This approach exemplifies TC in reducing the\n",
      "==================================================\n",
      "to the abstraction layer, not the application code. This approach exemplifies TC in reducing the effort and cost of major modifications.Architecture fitness function.  A fitness function is an invariant that verifies the persistence of desired system properties against changes.4 For example, a runtime fitness function might monitor response times to keep them under a set threshold, while a build-time fitness function might check for circular dependencies in the code. Fitness functions can be viewed as a form of TC, providing developers with automatic alerts to potential issues that could cause adverse effects down the line.Stateless services.  These services operate without maintaining conversational state, treating each request independently with request-specific state stored externally, like in a cache or database. They are a critical component of scalable applications as they allow the addition of service replicas and hardware instances without altering the code. Adopting stateless\n",
      "==================================================\n",
      "addition of service replicas and hardware instances without altering the code. Adopting stateless services creates TC by easing the scaling process to accommodate higher loads.Architecture decision records (ADRs).  ADRs document key architectural design decisions and the involved trade-offs, such as the results of a proof-of-concept prototype that led to the selection of a specific database over other candidates. ADRs simplify understanding a system’s architecture, creating TC by streamlining planning for future changes.Circuit Breakers.  This pattern is fundamental to building resilient micro-services-based systems, acting as safeguards against transient performance degradation or complete failures of called services. Circuit breakers are TC as they guard against cascading failures caused by slow responses to requests that lead to congestion, overload and eventual failure in calling services. They ensure system resilience and facilitate its evolution.Reference architectures (RAs).\n",
      "==================================================\n",
      "They ensure system resilience and facilitate its evolution.Reference architectures (RAs).  RAs capture the essence of the architecture of a collection of systems in a given domain, serving prescriptive, descriptive, and informative roles. They guide the development, standardization, and evolution of architectures within an application domain and aid decision-making by disseminating architectural knowledge. As such, RAs are a form of technical credit.A Research Agenda for Technical CreditWe believe TC warrants comprehensive investigation and scrutiny from the software engineering community. Analogous to technical debt, we see three broad areas of research to explore1: defining, comprehending, and operationalizing the concept of value in relation to TC, investigating phenomena closely related to how TC operates in practice, and establishing a shared infrastructure that enables all our research activities. Some specific research directions that can benefit from a more in-depth\n",
      "==================================================\n",
      "our research activities. Some specific research directions that can benefit from a more in-depth exploration of TC include:Identifying technical credit. How should a project team decide where to invest in technical credit? Answering this question involves careful evaluation of criteria such as potential architectural impact, cost-benefit analysis, and the likelihood of realizing the anticipated credit. All of these require insights into future product roadmaps and plans, which are inherently uncertain. Developing a solution to this challenge would allow teams to identify design decisions that are most likely to yield high payback. The ICE Scoring Method,a commonly used in product planning, offers a structured way to assess the impact, confidence, and ease of implementation for product features. Adapting a similar method could help in identifying the most promising areas for TC investment by quantifying their potential benefits.Tracking technical credit. How to benefit from technical\n",
      "==================================================\n",
      "by quantifying their potential benefits.Tracking technical credit. How to benefit from technical credit? To realize the benefits of TC, it is important for teams to be able to easily identify which TC items are generating value and which ones are not. This information can help teams to better understand the impact of their decisions and to make more informed ones in the future.Quantifying technical credit. How to measure technical credit? Tools like SonarQubeb can be used to quantify technical debt by estimating the effort to resolve it. In a similar way, teams need tools that can automatically recognize and value TC, helping to track its benefits and guide resource allocation for the greatest effect.Deriving product value. How to measure the return on investment (ROI)? If we can quantify both TD and TC, it may be possible to assign a value to individual design decisions, and to complete products. This could become a crucial factor in evaluating decisions and product ROI, along with\n",
      "==================================================\n",
      "products. This could become a crucial factor in evaluating decisions and product ROI, along with other elements such as revenue and customer satisfaction. However, determining how to calculate this value requires further investigation and research.ConclusionWe believe the concept of technical credit can positively impact the future of software engineering and hope this Opinion column inspires the software engineering research community to explore the concept. By identifying opportunities for practical implementation in conjunction with software practitioners, we can collectively bring this valuable concept into engineering practice.\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Refined strainer\n",
    "bs4_strainer = bs4.SoupStrainer(\n",
    "    class_=(\"article-contents\")\n",
    ")\n",
    "\n",
    "# Load page\n",
    "doc_loader = WebBaseLoader(\n",
    "    web_paths=[\"https://cacm.acm.org/opinion/technical-credit/\"],\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "\n",
    "documents = doc_loader.load()\n",
    "assert len(documents) == 1\n",
    "\n",
    "# Clean the page content and wrap back into Documents\n",
    "cleaned_documents = [\n",
    "    Document(page_content=\n",
    "             BeautifulSoup(\n",
    "                 doc.page_content,\n",
    "                 \"html.parser\"\n",
    "            ).get_text(), \n",
    "            metadata=doc.metadata)\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Split into chunks for LLM\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = splitter.split_documents(cleaned_documents)\n",
    "\n",
    "num_chars = 0\n",
    "article_chunks = \"\"\n",
    "for chunk in chunks:\n",
    "    num_chars += len(chunk.page_content)\n",
    "    article_chunks += f\"{chunk.page_content}\\n{'=' * 50}\\n\"\n",
    "\n",
    "print(f\"Total characters: {num_chars}\")\n",
    "print('=' * 50)\n",
    "print(f\"Split articles into {len(chunks)} chunks\")\n",
    "print('=' * 50)\n",
    "print(\"Article Chunks:\\n\\n\")\n",
    "print(article_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57093c26-c49c-454b-964d-985d99c027e1",
   "metadata": {},
   "source": [
    "* [X] test the web page document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2dcd6c-3469-4211-95bd-eadd65f86743",
   "metadata": {},
   "source": [
    "* [ ] split the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8341841c-23d3-40c8-83d0-b2187ac2c44a",
   "metadata": {},
   "source": [
    "* [X] embed the documents into vector database, DO NOT LOAD TWICE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd11df3-bfa5-418d-bd78-60ad0497b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = document_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd74688",
   "metadata": {},
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6178740-773d-432d-a533-45e2a4a21b4e",
   "metadata": {},
   "source": [
    "# RAG System Part\n",
    "## Customize Prompt\n",
    "## Define nodes and graphs in the rag system\n",
    "1. [X] retrieve code and metadata\n",
    "2. [X] retrieve academic documents\n",
    "3. [X] send message to LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93143ad-64df-4240-882f-e0b1d1d9b171",
   "metadata": {},
   "source": [
    "* [ ] design prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf3a43-d68d-4415-bb28-c321c42870b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context_doc', 'question', 'rendered'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are an assistant for identifying technical credit. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. For each code snippet, use three sentences maximum and keep the answer concise.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context_doc', 'question', 'rendered'], input_types={}, partial_variables={}, template='Some documentation about tech credit:\\n{context_doc}\\n\\nThe following are snippets of codes that are most similar to example codes of \\ntech credits.\\n{rendered}\\n\\nQuestion: {question}\\nAnswer:\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# Define prompt for question-answering\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "import textwrap\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from jinja2 import Environment, BaseLoader, StrictUndefined\n",
    "\n",
    "jinja2_prompt = \"\"\"\\\n",
    "{% for part in parts %}\n",
    "Here is part No. {{ part.ordinal }} of a tech credit.\n",
    "\n",
    "**Description**:  \n",
    "{{ part.tech_credit }}\n",
    "\n",
    "**Example Code**:  \n",
    "{{ part.context_code }}\n",
    "\n",
    "**User Code**:  \n",
    "{{ part.user_code }}\n",
    "\n",
    "{% endfor %}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_template = Environment(\n",
    "    loader=BaseLoader,\n",
    "    undefined=StrictUndefined,\n",
    "    trim_blocks=True,\n",
    "    lstrip_blocks=True\n",
    ").from_string(jinja2_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an assistant for identifying technical credit. Use the following pieces \"\n",
    "                \"of retrieved context to answer the question. If you don't know the answer, just \"\n",
    "                \"say that you don't know. For each code snippet, use three sentences maximum and \"\n",
    "                \"keep the answer concise.\"),\n",
    "    (\"user\", textwrap.dedent(\"\"\"\\\n",
    "                Some documentation about tech credit:\n",
    "                {context_doc}\n",
    "\n",
    "                The following are snippets of codes that are most similar to example codes of \n",
    "                tech credits.\n",
    "                {rendered}\n",
    "                \n",
    "                Question: {question}\n",
    "                Answer:\n",
    "                \"\"\"))\n",
    "    ])\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bf4cf-a257-4323-99b7-45d4fd92d73b",
   "metadata": {},
   "source": [
    "* [ ] collect metadata from code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba89a7a6-3c3f-4969-bdff-5cc6627d330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_unique_pairs(documents):\n",
    "    \"\"\"\n",
    "    Collect unique concatenated 'tech_credit: description' strings from document metadata.\n",
    "\n",
    "    Args:\n",
    "        documents (list[dict]): A list of Document objects, each with a 'metadata' field.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of unique 'tech_credit: description' strings.\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "\n",
    "    for doc in documents:\n",
    "        metadata = doc.metadata\n",
    "        credit = metadata.get(\"tech_credit\")\n",
    "        description = metadata.get(\"tech_credit_description\")\n",
    "        if credit and description:\n",
    "            combined = f\"{credit}: {description}\"\n",
    "            seen.add(combined)\n",
    "\n",
    "    print(seen)\n",
    "\n",
    "    return list(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e7fbf07-ec97-4bea-afe6-ba708826ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from statistics import mean, median # for later usage of different similarity score\n",
    "\n",
    "def default_min_score_fn(results: list[tuple[Document, float]]) -> float:\n",
    "    \"\"\"Default scoring function: returns the minimum score.\"\"\"\n",
    "    return min(score for _, score in results)\n",
    "\n",
    "def top_k_similar_queries(\n",
    "    queries: list[str],\n",
    "    vectorstore,\n",
    "    k: int = 3,\n",
    "    scoring_fn: Callable[[list[tuple[Document, float]]], float] = default_min_score_fn,\n",
    "    top_docs_per_query: int = 4\n",
    ") -> list[tuple[str, list[Document], float]]:\n",
    "    \"\"\"\n",
    "    Executes similarity_search_with_score for each query and returns top-k queries\n",
    "    sorted by a user-defined scoring function.\n",
    "\n",
    "    Args:\n",
    "        queries: List of query strings.\n",
    "        vectorstore: A LangChain-compatible vector store.\n",
    "        k: Number of top results to return.\n",
    "        scoring_fn: Function that maps a list of (Document, score) to a float score.\n",
    "        top_docs_per_query: Number of documents to retrieve for each query.\n",
    "\n",
    "    Returns:\n",
    "        A list of (query, documents, aggregated_score) sorted by aggregated_score descending.\n",
    "    \"\"\"\n",
    "    heap = []\n",
    "\n",
    "    for query in queries:\n",
    "        results = vectorstore.similarity_search_with_score(query, k=top_docs_per_query)\n",
    "        if not results:\n",
    "            continue\n",
    "\n",
    "        agg_score = scoring_fn(results)\n",
    "        \n",
    "        # if agg_score < 0.65:\n",
    "        #    continue\n",
    "    \n",
    "        docs = [doc for doc, _ in results]\n",
    "\n",
    "        # Use negative score to simulate a max-heap\n",
    "        heapq.heappush(heap, (-agg_score, query, docs))\n",
    "        if len(heap) > k:\n",
    "            heapq.heappop(heap)\n",
    "\n",
    "    # Return sorted results: highest score first\n",
    "    top_k = sorted([(-score, query, docs) for score, query, docs in heap], reverse=True)\n",
    "    return [(query, docs, score) for score, query, docs in top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad89e54e-0483-47d8-bda7-45e4ecec352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context_doc: List[Document]\n",
    "    # a part that contains example codes, user code, tech credit and index order\n",
    "    parts: list[dict]\n",
    "    url: str # user code\n",
    "    branch: str\n",
    "    answer: str\n",
    "\n",
    "def tojson(state: State) -> str:\n",
    "    def serialize_document(doc: Document) -> dict:\n",
    "        return {\n",
    "            \"page_content\": doc.page_content,\n",
    "            \"metadata\": doc.metadata,\n",
    "        }\n",
    "\n",
    "    # Shallow copy of state so we don’t mutate the original\n",
    "    serializable_state = dict(state)\n",
    "    serializable_state[\"context_doc\"] = [\n",
    "        serialize_document(doc) for doc in state[\"context_doc\"]\n",
    "    ]\n",
    "\n",
    "    return json.dumps(serializable_state, indent=2)\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    repo_splits = split_documents(load_repo(state[\"url\"], state[\"branch\"]))\n",
    "    retrieved_docs = top_k_similar_queries(repo_splits, vector_store)\n",
    "    parts = [\n",
    "        {\n",
    "            \"ordinal\": i + 1,\n",
    "            \"tech_credit\": \"\\n\".join(collect_unique_pairs(context_code)),\n",
    "            \"user_code\": user_code,\n",
    "            \"context_code\": \"\\n\\n\".join(doc.page_content for doc in context_code)\n",
    "        }\n",
    "        for i, (user_code, context_code, _) in enumerate(retrieved_docs)\n",
    "    ]\n",
    "    return {\"parts\": parts}\n",
    "\n",
    "def retrieve_doc(state: State):\n",
    "    retrieved_doc = document_store.similarity_search(state[\"question\"])\n",
    "    return {\"context_doc\": retrieved_doc}\n",
    "    \n",
    "def generate(state: State):\n",
    "    doc_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context_doc\"])\n",
    "    user_prompt = user_prompt_template.render(parts=state[\"parts\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"rendered\": user_prompt, \n",
    "                              \"context_doc\": doc_content})\n",
    "    print(tojson(state))\n",
    "    print(\"Messages: \", messages)\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_node(retrieve_doc)\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(START, \"retrieve_doc\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c890ef-9f4b-4f62-929b-64bc5b33b4c4",
   "metadata": {},
   "source": [
    "# Ask Question Part\n",
    "## Circuit Breaker\n",
    "## MVC model\n",
    "## Iterator pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb72313-9804-4db0-a3fe-ccd2841f9c6a",
   "metadata": {},
   "source": [
    "* [ ] Ask questions and test RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b8816-0600-47bb-8371-d010eaba2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\": \"Tell me what tech credits does the repo possibly use?\",\n",
    "\"url\": \"https://github.com/danielfm/pybreaker\", \"branch\": \"main\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e3468-c0b0-4ed2-9f12-9eaaa9403acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\": \"Tell me what tech credits does the repo possibly use?\",\n",
    "\"url\": \"https://github.com/zacernst/circuit_breaker\", \"branch\": \"master\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a574c51-5eeb-4581-9f96-a5ad263b8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\": \"Tell me what tech credits does the repo possibly use?\",\n",
    "\"url\": \"https://github.com/fabfuel/circuitbreaker\", \"branch\": \"develop\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b783b4-d5e7-4798-8964-aed0fc901c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\": \"Tell me what tech credits does the repo possibly use?\",\n",
    "\"url\": \"https://github.com/gmargari/pymvc\", \"branch\": \"main\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5be63f-a708-4608-9d98-b913cca422d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\": \"Tell me what tech credits does the repo possibly use?\",\n",
    "\"url\": \"https://github.com/etimberg/pycircuitbreaker\", \"branch\": \"master\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d3c6f-9ed7-41a3-ac7a-f12633aa2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = graph.invoke({\"question\": \"Tell me if the following is a tech credit and what do \n",
    "#       these 3 states do?\",\n",
    "# \"url\": \"https://github.com/pallets/jinja\", \"branch\": \"main\"})\n",
    "# print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe566a7-f5bf-4417-a90a-84ad342cf435",
   "metadata": {},
   "source": [
    "# Roadmap:\n",
    "\n",
    "1. Use a text embedding model.\n",
    "   + [X] gemini text-embedding-004\n",
    "2. Code splitter may not work properly.\n",
    "   + [X] change to code-splitter that works better.\n",
    "3. [X] Switch in memory vector storage to a vector database\n",
    "   + [X] code vector database with additional metadata for tech credit\n",
    "   + [X] document vector database with academic context about tech credit\n",
    "4. [ ] Load more standard example codes for tech credit (~20 more examples)\n",
    "5. [ ] Load more documents (academic contexts) for technical credit (3~5 related academic paper)\n",
    "6. [X] Allow user to ask about a repository, instead of small snippets of codes\n",
    "   * [X] load, chunk, split, embed and vectorize a repo\n",
    "   * [X] similarity search and filter user code by similarity score compared with example code\n",
    "   * [ ] batch process to LLM\n",
    "   * [ ] organize response and answers\n",
    "7. [ ] validate the results\n",
    "   * [ ] Test our trained data in TC-Examples\n",
    "   * [ ] use different embedding and LLM to test five example repos\n",
    "   * Gemini, \n",
    "   * claude-3.5-haiku,\n",
    "8. Jun 6:\n",
    "   1. [ ] choose five test repos\n",
    "   2. [ ] two more LLM and one more embeddings models\n",
    "   3. [ ] expected output:\n",
    "      1. [ ] human expert\n",
    "      2. [ ] LLM as judge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
